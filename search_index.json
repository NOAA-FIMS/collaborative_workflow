[["index.html", "FIMS Developer Handbook Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " FIMS Developer Handbook FIMS implementation team 2022-02-18 Chapter 1 About This is a book written in Markdown describing the FIMS development workflow. This section describes how to edit and contribute to the book. 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["code-of-conduct.html", "Chapter 2 Code of Conduct 2.1 FIMS Contributor Conduct 2.2 Supporting Good Conduct", " Chapter 2 Code of Conduct 2.1 FIMS Contributor Conduct All contributors participating and contributing to the FIMS project are expected to adhere to the Contributor Covenant. Briefly, these standards are adopted to ensure a positive and harassment-free enviroment for all participants. Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community 2.2 Supporting Good Conduct FIMS Community leaders will create default community health files (e.g. CONTRIBUTING, CODE_OF_CONDUCT) to be used in all repositories owned by FIMS. 2.2.1 Reporting Unacceptable Behavior Questions about the FIMS Code of Conduct or reports of unacceptable behavior should be sent to fims.conduct@noaa.gov. Reports will be reviewed by a member of the NOAA Fisheries Office of Science and Technology who is not participating in the FIMS Project [Jim Berkson], but has the full support of FIMS Community Leaders. All reports will be reviewed promptly and fairly. 2.2.2 Consequences of Violating Conduct People who violate the FIMS Contribute Conduct will face meaningful consequences, up to and including explusion from the FIMS Community. The Code of Conduct, as well as consequences for violations, apply equally to all participants. "],["style-guide.html", "Chapter 3 Style Guide", " Chapter 3 Style Guide The FIMS project uses style guides to ensure our code is consistent, easy to use (e.g. read, share, and verify), and ultimately easier to write. We use the Google C++ Style Guide and Google’s R Style Guide. Google’s R Style Guide is based off of the tidyverse style guide, with a few minor modifications to improve readability and portability. "],["fims-governance.html", "Chapter 4 FIMS Governance 4.1 Developers 4.2 C++ developers 4.3 R developers 4.4 Reviewers 4.5 Project Lead 4.6 Director Of Software Development 4.7 Code of Conduct Enforcement 4.8 External Collaborators", " Chapter 4 FIMS Governance The FIMS Terms of Reference describes the high level organization of the FIMS Project. Additional details on roles and responsibilities are provided here. 4.1 Developers Developers are expected to adhere to the principles and guidelines outlined within this handbook, including the Code of Conduct, Style Guide, Issue Tracking, and Test Case Template. 4.2 C++ developers The C++ developer responsibilities include: Writing the module code. Creating documentation for the module and building the documentation in doxygen to ensure it is error-free. Implementing the suite of required test cases in Google Test for the module. Ensuring the module runs through the FIMS Github actions. Once development of a bug fix or a new component of FIMS is complete, the developer should create a pull request according to the correct template and assign the issue tracking the completion of the bug fix and/or feature to the assigned review team. The developer must resolve any issues arising from the review and get confirmation from the review team before the pull request is merged into the upstream branch. 4.3 R developers The R developers responsibilities include * Writing the Rcpp interface to the C++ code. * Writing Roxygen documentation for any R functions * Writing testthat() test cases for any R functionality * Ensuring the code passes the R CMD CHECK, styler, and any other automated checks. Once these are complete, the developer should create a pull request according to the correct template and assign the issue tracking the completion of the bug fix and/or feature to the assigned review team. The developer must resolve any issues arising from the review and get confirmation from the review team before the pull request is merged into the upstream branch. 4.4 Reviewers The reviewers are responsible for adhering to documented guidelines in the Code Review section. Reviewers should confirm that the new code is able to build and run within their own development environment as well as via the Github actions on the repository. Reviewers should clearly document which components of the code need to be improved to be accurate, comply with project guidelines and style, or do not work, in the pull request thread so that the developer knows what they need to fix. 4.5 Project Lead The Project Lead is responsible for ensuring development and code review occur in a timely manner and according to project guidelines and standards. The Project Lead will triage issues and pull requests weekly and prompt involved parties to resolve outstanding issues and reviews. The Project Lead is also responsible for communicating project status via maintenance of the status dashboard. 4.6 Director Of Software Development The Director of Software Development is responsible for the successful creation and delivery of the FIMS product to the end user by managing technical risks and opportunities; making key software design and implementation decisions with the development teams, scheduling of tasks, managing change requests, and guaranteeing quality of deliveries and educating the team on technical best practices. 4.7 Code of Conduct Enforcement The Code of Conduct enforcer is responsible for responding to allegations of Code of Conduct violations in an appropriate manner. This could include a conversation with the violator, his or her manager, up to and including expulsion from the FIMS development team. If the violator is an external collaborator, they can be banned from contributing to the FIMS Github resources in the future. 4.8 External Collaborators External collaborators interested in contributing to FIMS development are required to fork the FIMS repository, make changes, and submit a pull request. However, collaborators are strongly encouraged to submit an issue via the main FIMS repository for discussion prior to forking. In general, forks are discouraged for development that is intended for integration into FIMS as it becomes difficult to keep track of multiple forks. If collaborators wish to use FIMS as a starting-point for a brand new project that they do not intend to merge back into the main branch, they can start a fork. However, if they intend to create a pull request, they should use a branch. Pull requests from forks will be reviewed the same as a pull request submitted from a branch. Users will need to conform to the same standards and all contributions must pass the standard tests as well as provide tests that check the new feature. "],["contributor-guidelines.html", "Chapter 5 Contributor Guidelines 5.1 FIMS Branching Strategy 5.2 Coding Good Practices", " Chapter 5 Contributor Guidelines External contributions and feedback are important to the development and future maintenance of FIMS and are welcome. This section provides information for FIMS developers and collaborators on how to contribute to the project. 5.1 FIMS Branching Strategy There are several branching strategies available that will work within the Git environment and other version control systems. However, it is important to find a strategy that works well for both current and future contributors. Branching strategies provide guidance for how, when, and why branches are created and named, which also ties into necessary guidance surrounding issue tracking. The FIMS Project uses a Scaled Trunk Based Development branching strategy to make tasks easier without compromising quality. Scaled Trunk Based Development; image credit: https://reviewpad.com/blog/github-flow-trunk-based-development-and-code-reviews/ This strategy is required for continuous integration and facilitates knowledge of steps that must be taken prior to, during, and after making changes to the code, while still allowing anyone interested in the code to read it at any time. Additionally, trunk-based development captures the following needs without being overly complicated: Short-lived branches to minimize stale code and merge conflicts Fast release times, especially for bug fixes Ability to release bug fixes without new features 5.1.1 Branching Good Practices The following suggestions will help ensure optimal performance of the trunk-based branching strategy: Branches and commits should be kept small (e.g. a couple commits, a few lines of code) to allow for rapid merges and deployments. Use feature flags to wrap new changes in an inactive code path for later activation (rather than creating a separate repository feature branch). Delete branches after it is merged to the trunk; avoid repositories with a large number of “active” branches. Merge branches to the trunk frequently (e.g. at least every few days; tag as a release commit) to avoid merge conflicts. Use caching layers where appropriate to optimize build and test execution times. 5.1.2 Branch Protection Branch protection allows for searching branch names with grep functionality to apply merging rules (i.e., protection). This will be helpful to protect the main/trunk branch such that pull requests cannot be merged in prior to passing various checks or by individuals without the authority to do so. 5.2 Coding Good Practices Following good software development and coding practices simplifies collaboration, improves readability, and streamlines testing and review. The following are industry-accepted standards: Adhere to the FIMS Project style guide Avoid rework - take the time to check for existing options (e.g. in-house, open source, etc.) before writing code Keep code as simple as possible Use meaningful variable names that are easy to understand and clearly represent the data they store Use descriptive titles and consistent conventions for class and function names Use consistent names for temporary variables that have the same kind of role Add clear and concise coding comments Use consistent formatting and indentation to improve readability and organization Group code into separate blocks for individual tasks Avoid hard-coded values to ensure portability of code Follow the DRY principle - “Don’t Repeat Yourself” (or your code) Avoid deep nesting Limit line length (wrap ~72 characters) Capitalize SQL queries so they are readily distinguishable from table/column names Lint your code "],["issue-tracking.html", "Chapter 6 Issue Tracking 6.1 Issue Labels 6.2 Issue Templates 6.3 Issue Lifecycle 6.4 Pull Requests 6.5 Code Review 6.6 Commit Messages", " Chapter 6 Issue Tracking Use of the GitHub issue tracker is key to keeping everyone informed and prioritizing key tasks. All future projects, ideas, concerns, development, etc. must be documented in an issue before the code is altered. Issues should be filed and tagged prior to any code changes whether the change pertains to a bug or the development of a feature. At a minimum, all issues will be labeled with a future version number. Bugs with immediate fixes will be assigned to the current version number augmented for a hot fix and development will be based on code in the trunk. All other issues will be assigned to a future version and development will be based on version branches. That is, changes to the code for version 3.3 cannot start until there is a branch for version 3.3. This will minimize stale code and large merge conflicts. 6.1 Issue Labels Utilize labels on issues: To describe the kind of work to be done: bug, enhancement, task, discussion, question, suitable for beginners To indicate the state of the issue: urgent, current, next, eventually, won’t fix, duplicate 6.2 Issue Templates There are two issue templates currently available in the FIMS repository. 1. Feature requests: this template should be used to request new features or changes to features, such that the described functionality differs from what is currently in the development plan. 2. Bug reports: this should be used to file bugs, which describe when the existing functionality differs from what is described in the development plan. 6.3 Issue Lifecycle FIMS development will adhere to a lifecycle for issues that makes it clear which issues can be resolved when. Creation — The event that marks the creation of an issue. An issue is not Active when it is Created. Issues that are opened are assigned to the FIMS Project Lead with the label: needs-triage. A issue is not considered Active until this label is removed. Activation — When the needs-triage label is removed and the issue is assigned to a developer, the issue becomes Active. This event happens once in the lifecycle of an issue. Activation usually is not undone but it can be undone if an issue needs additional discussion; in this case, the needs-triage label is applied again. An issue is Active from the time it is Activated until reaches Resolution. Response — This event only happens if the triage team deems an issue to a wont-fix or delayed. This requires communication with the party who opened the issue as to why this will not be addressed or will be moved to a later milestone. Resolution — The event that marks the resolution of an issue. This event happens once in the lifetime of an issue. This event can be undone if an issue transitions from a resolved status to an unresolved status, in which case the system considers the issue as never had been resolved. A resolution involves a code check-in and pull request, at which point someone must review and approve the pull request before the issue can transition states. In Review - The issue is “in review” after a code solution has been proposed and is being considered via a pull request. If this is approved, the issue can move into the “Closed” state. Closure—The event that marks the closure of an Issue. This even happens once in the lifetime of an issue. The issue can enter the Closed state from either the “In Review” or “Response” state. Figure 6.1: Flow chart that describes above process visually, e.g. how an issue moves from creation, to activation, to response or resolution, and is finally closed. 6.4 Pull Requests Pull requests are used to identify changes pushed to development branches. Open pull requests allow the FIMS Development Team to discuss and review the changes, as well as add follow-up commits before merging to the main branch. As noted above in the branching stratgegy section, branches, commits, and pull requests should be kept small to enable rapid review and reduce the chance of merge conflicts. Any pull requests for the FIMS Project must be fully tested and reviewed before being merged into the main branch. Use the pull request template to create pull requests. Pull requests without this template attached will not be approved. 6.5 Code Review Code review ensures health and continuous improvement of the FIMS codebase, while simultaneously helping FIMS developers become familiar with the codebase and ensure there is a diverse team of knolwedgable collaborators to support the continued development and maintenance of FIMS. CI/CD requires rapid review of all new/modified code, so processes must be in place to support this pace. FIMS code review will utilize tools available via GitHub, which allows reviewers to analyze code changes, provide inline comments, and view change histories. 6.5.1 Assigning Reviewers Reviewers for the FIMS Project may be assigned in two different ways: A specific member of the FIMS Development Team is requested to review a pull request, based on their specific expertise. Code review assignments are automatically assigned using the GitHub load balance routing algorithm; this approach tries to ensure that each team member reviews an equal number of pull request in any 30 day period. Team members should keep their status in Github current (see “Setting a status” for more information). Reviews will not be auto-assigned to “Busy” team members. If a review has been assigned to you and you don’t feel like you have the expertise to address it properly, please respond directly to the code owner immediately so a different reviewer can be found promptly. 6.5.2 Automated Testing Automated testing provides an initial layer of quality assurance and lets reviewers know that the code meets certain standards. For more on FIMS testing, see Chapter 6. 6.5.3 Review Checklist While automated testing can assure the code structure and logic pass quality checks, human reviewers are required to evaluate things like functionality, readability, etc. Reviewers should evaluate the code critically and provide comment/feedback on the following items: Readability Is the code easy to understand? Are there any parts of the code that are confusing? Is the data flow easy to understand? Is there any code commented out? Does the code include any unclear names? Does the code include any errors, repeats, or incomplete sections? Functionality Does the code function as it is expected to? How will the change impact other parts of the system? Are there any unhandled edge cases? Are there other code improvements possible? Design Are files organized intuitively? Are components divided up in a sensible way? Does the review include too many changes? Would the code change better be broken into more focused parts? Will the change be easy to maintain? Does the code follow object-oriented design principles? Is the code in the proper location? Security Does using this code open the software to possible security violations or vulnerabilities? Is the correct encryption used? Performance Are there ways to improve on the code’s performance? Is there any complex logic that could be simplified? Could any of the code be replaced with built-in functions? Will this change have any impacts on system performance? Is there any debugging code that could be removed? Are there any optimizations that could be removed and still maintain system performance? Documentation Are there comments available to explain the code? Is the README file complete and current? Does it adequately describe the project/changes? Testing Is the code testable? Is the automated testing adequate? Have dependencies been appropriately tested? Does automated testing cover the code exchange adequately? Could the test structure be improved? 6.5.4 Review Good Practices Good reviews require good review habits. Try to follow these suggestions: Review in short sessions (&lt; 60 minutes) to maintain focus and attention to detail Don’t try to review more than 400 lines of code in a single session Provide constructive and supportive feedback Ask open-ended questions and offer alternatives or possible workarounds Avoid strong/opinionated statements Applaud good solutions Don’t say “you” Be clear about which questions/comments are non-blocking or unimportant; likewise, be explicit when approving a change or requesting follow-up Aim to minimize the number of nitpicks (if there are a lot, suggest a team-level resolution) Use the FIMS Style Guide to settle any style arguments 6.6 Commit Messages FIMS Project contributors should provide clear, descriptive commit messages to communicate to collaborators details about changes that have occurred and improve team efficiency. Good commit messages follow the following practices: Include a short summary of the change for the subject/title (&lt;50 characters) Include a blank line in between the ‘subject’ and ‘body’ Specify the type of commit: * fix: bug fix * feat: new feature * test: testing * docs: documentation * chore: regular code maintenance (e.g. updating dependencies) * refactor: refactoring codebase * style: changes that do not affect the meaning of the code; instead address code styling/formmatting * perf: performance improvements * revert: reverts a previous commit * build: changes that affect the build system If the commit addresses an issue, indicate the issue# in the title Provide a brief explanatory description of the change, addressing what and why was changed Wrap to ~72 characters Write in the imperative (e.g. “Fix bug”, not “Fixed bug”) If necessary, separate paragraphs by blank lines Utilize BREAKING CHANGE: &lt;description&gt; to provide expanation or further context about the issue being addressed. If the commit closes an issue, include a footer to note that (i.e. “Closes #19”) "],["software-user-guide.html", "Chapter 7 Software user guide 7.1 Installing the package from Github 7.2 Installing from R 7.3 Specifying and compiling the model 7.4 Extracting model output", " Chapter 7 Software user guide This section describes how to install and run the model. 7.1 Installing the package from Github 7.1.1 Windows users Before you install the FIMS package, you will need to install the Rtools executable corresponding to your R version as well as the TMB package and its dependencies. FIMS has only been developed and tested on R version 4.+, and so in order to install the package you will need to ensure you are using R version 4.+ and an RStudio version that is at least 1.2.5042. Instructions on how to install Rtools are here. Instructions on how to install TMB are here. Please ensure you have tested your TMB setup before moving on to install FIMS. 7.1.2 Mac users 7.1.3 Linux users 7.2 Installing from R remotes::install_github(&quot;NOAA-FIMS/FIMS&quot;) library(FIMS) 7.3 Specifying and compiling the model You can add components to the model using S4 classes. #TODO: add script to populate the model 7.4 Extracting model output Here is how you get the model output. #Todo add code for how to extract model output "],["software-developer-guide.html", "Chapter 8 Software developer guide 8.1 git 8.2 Development environment 8.3 C++ compiler 8.4 Google test", " Chapter 8 Software developer guide This section describes the software you will need to contribute to this project. This is in addition to the software dependencies described in the software user guide which you should ensure are installed first. 8.1 git You will need git installed locally, and you may prefer to use an additional git GUI client such as GitKraken or Github Desktop. If your preferred git client is the RStudio IDE, you can configure Git and RStudio integration following these instructions. To install git, please follow the instructions on this page for your operating system. You can find the downloads for your operating system on the left-hand navigation bar on that page. 8.2 Development environment An integrated development environment is recommended to organize code files, outputs, and build and debug environments. The most popular IDEs on the development team are RStudio and Visual Studio Code. You are welcome to use another IDE if you’d like. 8.3 C++ compiler Windows users who installed Rtools should have a C++ compiler (gcc) as part of the bundle. To ensure the C++ compiler is on your path, open a command prompt and type gcc. If you get the below message, you are all set: gcc: fatal error: no input files compilation terminated. If not, you will need to check that the compiler is on the path. The easiest way to do so is by creating a text file .Renviron in your Documents folder which contains the following line: PATH=&quot;${RTOOLS40_HOME}\\usr\\bin;${PATH}&quot; You can do this with a text editor, or from R like so (note that in R code you need to escape backslashes): write(&#39;PATH=&quot;${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}&quot;&#39;, file = &quot;~/.Renviron&quot;, append = TRUE) Restart R, and verify that make can be found, which should show the path to your Rtools installation. Sys.which(&quot;make&quot;) ## &quot;C:\\\\rtools40\\\\usr\\\\bin\\\\make.exe&quot; 8.4 Google test You will need to install CMake and ninja and validate you have the correct setup by following the steps outlined in the test case template. "],["model-specification.html", "Chapter 9 Model specification 9.1 Model variables and bounds 9.2 Inherited functors from TMB 9.3 Beverton-Holt expected recruitment function 9.4 Logistic function with extensions 9.5 Catch and fishing mortality 9.6 Modeling loops 9.7 Expected numbers and quantities 9.8 Initial values 9.9 Likelihood calculations", " Chapter 9 Model specification This section describes the implementation of the modules in FIMS in milestone 1. For the first milestone, we must implement enough complexity to adequately test a very standard population model. For this reason, we implement the minimum structure that can run the model described in Li et al. 2020. 9.1 Model variables and bounds 9.2 Inherited functors from TMB 9.2.1 Atomic functions Wherever possible, FIMS should not reinvent atomic functions with extant definitions in TMB. If there is a need for a new atomic function the development team can add it to TMB using the TMB_ATOMIC_VECTOR_FUNCTION() macro following the instructions here. 9.2.2 Statistical distributions All of the statistical distributions needed for the first milestone of FIMS are implemented in TMB and need not be replicated. Code can be found here. Distribution Name Normal dnorm Multinomial dmultinom 9.3 Beverton-Holt expected recruitment function For parity with existing stock assessment models, the first recruitment option in FIMS is a Beverton-Holt [cite] parameterized with R0 and h. \\[R_t =\\frac{0.8R_0hS_{t-1}}{0.2R_0\\phi_0(1-h) + S_{t-1}(h-0.2)}\\] Where \\(R_t\\) and \\(S_t\\) are mean recruitment and spawning biomass in time \\(t\\), \\(h\\) is Mace-Doonan steepness, and \\(\\phi_0\\) are the unfished spawning biomass per recruit. The initial FIMS model will implement a static spawning biomass-per-recruit function, with the ability to overload the method in the future to allow for time-variation in mortality, maturity, and weight-at-age over time to account for changes in spawning biomass per recruit. Deviations are assumed to be lognormally distributed such that realized recruitment is the product of mean recruitment and the exponentiated recruitment deviation. \\[R_t = R_t\\mathrm{exp}(r_{dev,t}-R^2/2), r_{dev,t} \\sim N(0,R^2)\\] However, true \\(r_{dev,t}\\) values are not known, so when using estimated recruitment deviations \\(\\hat{r_{dev,t}}\\) the following equation is applied to calculate mean unbiased recruitment \\(R*_t\\) using a bias adjustment factor \\(b_y=\\frac{E[SD(ry)]^2}{\\sigma_R^2}\\) (Methot and Taylor, 2011). \\[R^*_t=R_t\\mathrm{exp}(\\hat{r_{dev,t}}-b_y\\frac{\\sigma_R^2}{2})\\] The recruitment function should take as input the \\(R\\) , \\(S\\) values, the \\(h\\), \\(ln(R_0)\\), and R parameters and \\(\\phi_0\\) and return mean and realized recruitment. 9.4 Logistic function with extensions \\[x_i=\\frac{1}{1+\\mathrm{exp}(-ln(19)(i-\\nu_1)/\\nu_2)}\\] Where \\(x_i\\) is the quantity of interest (proportion mature, selected, etc.), \\(i\\) is the index (can be age or size or any other quantity), \\(\\nu_1\\) is the index of 50% mature and \\(\\nu_2\\) is the difference in the index at 50% and the index at 95% (\\(\\nu_2 = \\mathrm{ln}(19)/s\\) where \\(s\\) is the slope parameter from an alternative parameterization). Logistic functions for maturity and selectivity should inherit and extend upon the base logistic function implementation. 9.5 Catch and fishing mortality The Baranov catch equation relates catch to instantaneous fishing and natural mortality. \\[ C_{f,a,t}=\\frac{F_{f,a,t}}{F_{f,a,t}+M}(1-\\mathrm{exp}(-(F_{f,a,t}+M)))N_{a,t}\\] Where \\(C_{f,a,t}\\) is the catch at age \\(a\\) at time \\(t\\) for fleet \\(f\\), \\(F\\) is instantaneous fishing mortality, \\(M\\) is assumed constant over ages and time in the minimum viable assessment model, \\(N_a,t\\) is the number of age \\(a\\) fish at time \\(t\\). \\[F_{a,t}=\\sum_{a=0}^A s_{a,f,t}F\\] \\(s_a,f\\) is selectivity at age \\(a\\) for fleet \\(f\\). Selectivity-at-age is constant over time. Catch is in metric tons and survey is in number, so calculating catch weight (\\(CW_t\\)) is done as follows: \\[ CW_t=\\sum_{a=0}^A C_{a,t}w_a \\] Survey numbers are calculated as follows \\[I_t=q\\sum_{a=0}^AN_{a,t}\\] Where \\(I_t\\) is the survey index and \\(q_t\\) is survey catchability at time \\(t\\). 9.6 Modeling loops This tier associates the expected values for each population section associated with a data source to that data source using a likelihood function. These likelihood functions are then combined into an objective function that is passed to TMB. The population loop will be initialized at a user-specified age, time increment, and seasonal structure, rather than assuming ages, years, or seasons follow any pre-defined structure. Population categories will be described flexibly, such that subpopulations such as unique sexes, stocks, species, or areas can be handled identically to reduce duplication. Each subpopulation will have a unique set of attributes assigned to it, such that each subpopulation can share or have a different functional process (e.g. recruitment function, size-at-age) than a different category. Spawning time and recruitment time are user-specified and can occur more than once per year. For the purposes of replicating model comparison project outputs, in milestone 1, all processes including spawning and recruitment occur January 1, but these should be specified via the spawn_time and recruit_time inputs into FIMS to allow for future flexibility. Spawning and recruitment timing can be input as a scalar or vector to account for multiple options. Within the population loop, matrices denoting population properties at different partitions (age, season, sex) are translated into a single, dimension-folded index. A lookup table is computed at model start so that the dimension-folded index can be mapped to its corresponding population partition or time partition (e.g. population(sex, area, age, species, time, …)) so the programmer can understand what is happening. The model steps through each specified timestep to match the data to expected values, and population processes occur in the closest specified timestep to the user-input process timing (e.g. recruitment) across a small timestep that is a predefined constant. 9.7 Expected numbers and quantities The expected values are calculated as follows in the population.hpp file: \\[ B_t=\\sum_{a=0}^AN_{a,t}w_a\\] where \\(B_t\\) is total biomass in time \\(t\\), \\(N\\) is total numbers, \\(w_a\\) is weight-at-age \\(a\\) in kilograms. \\[N_t=\\sum_{a=0}^AN_{a,t}\\] where \\(N_t\\) is the total number of fish in time \\(t\\). 9.8 Initial values 9.8.1 Initial N 9.8.2 Initial F 9.9 Likelihood calculations Age composition likelihood links proportions at age from data to model using a multinomial likelihood function. The multinomial and lognormal distributions, including atomic functions are provided within TMB. Survey index likelihood links estimated CPUE to input data CPUE in biomass using a lognormal distribution. (model.hpp) Catch index likelihood links estimated catch to input data catch in biomass using a lognormal distribution. (model.hpp) Age composition likelihoods link catch-at-age to expected catch-at-age using a multinomial distribution. "],["hpp-template-for-c-modules.html", "Chapter 10 .hpp template for C++ modules", " Chapter 10 .hpp template for C++ modules In this section we will describe how to structure a new .hpp file in FIMS. // tmplate.hpp // Fisheries Integrated Modeling System (FIMS) //define the header gaurd #ifndef template_hpp #define template_hpp //inherit from model_base #include &quot;../common.hpp&quot; #include &lt;iostream&gt; /** * In this example, we utilize the concept of inheritence and * polymorphism (https://www.geeksforgeeks.org/polymorphism-in-c/). All * classes inherit from model_base. Name1 and Name2 inherit from NameBase. * Classes Name1 and Name2 must implement they&#39;re own version of * &quot;virtual T evaluate(const T&amp; t)&quot;, which will have unique logic. */ /* * fims namespace */ namespace fims{ /** * NameBase class. Inherits from model_base. */ template &lt;class T&gt; class NameBase: public model_base&lt;T&gt;{ //note that model_base gets template parameter T. protected: public: virtual T Evaluate(const T&amp; t)=0; //&quot;= 0;&quot; means this must be implemented in child. }; /* * Template class inherits from NameBase */ template &lt;class T&gt; class Name1: public NameBase&lt;T&gt;{ public: /* *Default constructor *Initialize any memory here. */ Name1(){ } /** * Destructor; this method destructs Name1 object. * Delete any allocated memory here. */ ~ Name1(){ std::cout &lt;&lt;&quot;I just deleted Name1 object&quot; &lt;&lt; std::endl; } /** * Note: this function must have the same signature as evaluate in NameBase. * Overloaded virtual function. This is polymorphism, meaning the * signature has the same appearance, but the function itself has unique logic. * * @param t * @return t+1 */ virtual T Evaluate(const T&amp; t) { std::cout&lt;&lt;&quot;evaluate in Name1 received &quot;&lt;&lt;t&lt;&lt; &quot;as a method parameter, returning &quot;&lt;&lt;(t+1)&lt;&lt;std::endl; return t+1; //unique logic for Name1 class } }; /* * Template class inherits from NameBase */ template &lt;class T&gt; class Name2: public NameBase&lt;T&gt;{ public: /* *Default constructor. *Initialize any memory here. */ Name2(){ } /** * Destructor; this method destructs the Name2 object. * Delete any allocated memory here. */ ~ Name2(){ std::cout &lt;&lt;&quot;I just deleted Name2 object&quot; &lt;&lt; std::endl; } /** * Note: this function must have the same signature as evaluate in NameBase. * Overloaded virtual function. This is polymorphism, meaning the * signature has the same appearance, but the function itself has unique logic. * * @param t * @return t^2 */ virtual T Evaluate(const T&amp; t) { std::cout&lt;&lt;&quot;evaluate in Name2 received &quot;&lt;&lt;t&lt;&lt; &quot;as a method parameter, returning &quot;&lt;&lt;(t*t)&lt;&lt;std::endl; return t*t; //unique logic for Name2 class } }; /** * Add additional implementations below. */ } //end namespace /** *Example usage: * * void main(int argc, char** argv){ * NameBase&lt;double&gt;* name = NULL; //pointer to a NameBase object * Name1&lt;double&gt; n1; //inherits from NameBase * Name2&lt;double&gt; n2; //inherits from NameBase * * name = &amp;n1; //name now points to n1 * name-&gt;Evalute(2.0); //unique logic for n1 * * name = &amp;n2; //name now points to n2 * name-&gt;Evalute(2.0); //unique logic for n2 * } * * Output: * evaluate in Name1 received 2 as a method parameter, returning 3 * evaluate in Name2 received 2 as a method parameter, returning 4 * */ #endif /*template_hpp */ "],["test-case-template.html", "Chapter 11 Test case template 11.1 Introduction 11.2 C++ unit testing and benchmarking 11.3 R testing 11.4 Test case template and examples 11.5 Glossary", " Chapter 11 Test case template In this section we will describe how to write a test case for your FIMS code. 11.1 Introduction FIMS testing framework will include different types of testing to make sure that changes to FIMS code are working as expected. The unit and functional tests will be developed during the initial development stage when writing individual functions or modules. After completing development of multiple modules, integration testing will be developed to verify that different modules work well together. Checks will be added in the software to catch user input errors when conducting run-time testing. Regression testing and platform compatibility testing will be executed before pre-releasing FIMS. Beta-testing will be used to gather feedback from users (i.e., members of FIMS implementation team and other users) during the pre-release stage. After releasing the first version of FIMS, the development team will go back to the beginning of the testing cycle and write unit tests when a new feature needs to be implemented. One-off testing will be used for testing new features and fixing user-reported bugs when maintaining FIMS. More details of each type of test can be found in the Glossary section. FIMS will use GoogleTest to build a C++ unit testing framework and R testthat to build an R testing framework. FIMS will use Google Benchmark to measure the real time and CPU time used for running the produced binaries. 11.2 C++ unit testing and benchmarking 11.2.1 Requirements To use GoogleTest, you will need: A compatible operating system (e.g. Windows, masOS, or Linux). A C++ compiler that supports at least C++ 11 standard or newer (e.g. gcc 5.0+, clang 5.0+, or MSVC 2015+). For macOS users, Xcode 9.3+ provides clang 5.0. A build system for building the testing project. CMake and a compatible build tool such as Ninja are approved softwares by NMFS HQ. 11.2.2 Quickstart for Windows user Download CMake 3.22.1 (cmake-3.22.1-windows-x86_64.zip) and put the file folder to Documents\\Apps or other preferred folder. Download ninja v1.10.2 (ninja-win.zip) and put the application to Documents\\Apps or other preferred folder. Search Edit environment variables for your account and open the Environment Variables window. Click Edit... under the User variables for firstname.lastname section. Click New, add path to cmake-3.22.1-windows-x86_64\\bin, add click OK. Click New, add path to Documents\\Apps, add click OK. Open your Command Prompt and type cmake. If you see details of usage, you install the build system successfully. See CMake installation instructions for installing CMake on other platforms. 11.2.3 Set up FIMS testing project Go to the FIMS C++ tests folder and create a CMakeLists.txt file. Declare a dependency on GoogleTest with following contents: cmake_minimum_required(VERSION 3.14) project(FIMS_project) # GoogleTest requires at least C++11 set(CMAKE_CXX_STANDARD 11) include(FetchContent) FetchContent_Declare( googletest URL https://github.com/google/googletest/archive/refs/tags/release-1.11.0.zip ) # For Windows: Prevent overriding the parent project&#39;s compiler/linker settings set(gtest_force_shared_crt ON CACHE BOOL &quot;&quot; FORCE) FetchContent_MakeAvailable(googletest) If a CMakeLists.txt file already exists in the tests folder, you can start creating a unit test and add it to the CMakeLists.txt. 11.2.4 Unit test template #include &quot;gtest/gtest.h&quot; #include &quot;../src/code.hpp&quot; // # R code that generates true values for the test namespace { // Description of Test 1 TEST(TestSuiteName, Test1Name) { ... test body ... } // Description of Test 2 TEST(TestSuiteName, Test2Name) { ... test body ... } } 11.2.5 Unit test example Let’s create dlognorm.hpp that has a simple function: #include &lt;cmath&gt; template&lt;class Type&gt; Type dlognorm(Type x, Type meanlog, Type sdlog){ Type resid = (log(x)-meanlog)/sdlog; Type logres = -log(sqrt(2*M_PI)) - log(sdlog) - Type(0.5)*resid*resid - log(x); return logres; } We can create a test file dlognorm-unit.cpp that has a test suite for this function: #include &quot;gtest/gtest.h&quot; #include &quot;../src/dlognorm.hpp&quot; // # R code that generates true values for the test // dlnorm(1.0, 0.0, 1.0, TRUE) = -0.9189385 // dlnorm(5.0, 10.0, 2.5, TRUE) = -9.07679 namespace { // TestSuiteName: dlognormTest; TestName: DoubleInput and IntInput // Test dlognorm with double input values TEST(dlognormTest, DoubleInput) { EXPECT_NEAR( dlognorm(1.0, 0.0, 1.0) , -0.9189385 , 0.0001 ); EXPECT_NEAR( dlognorm(5.0, 10.0, 2.5) , -9.07679 , 0.0001 ); } // Test dlognorm with integer input values TEST(dlognormTest, IntInput) { EXPECT_NE( dlognorm(1, 0, 1) , -0.9189385 ); } } EXPECT_NEAR(val1, val2, absolute_error) verifies that the difference between val1 and val2 does not exceed the absolute error bound absolute_error. EXPECT_NE(val1, val2) verifies that val1 is not equal to val2. Please see GoogleTest assertions reference for more EXPECT_ macros. 11.2.6 Add tests to CMakeLists.txt and run a binary To build the code, add the following contents to the end of your CMakeLists.txt file: enable_testing() add_executable( dlognorm_test dlognorm-unit.cpp ) target_include_directories( dlognorm_test PUBLIC ${CMAKE_SOURCE_DIR}/../ ) target_link_libraries( dlognorm_test gtest_main ) include(GoogleTest) gtest_discover_tests(dlognorm_test) The above configuration enables testing in CMake, declares the C++ test binary you want to build (dlognorm_test), and links it to GoogleTest (gtest_main). Now you can build and run your test: cd tests cmake -S . -B build -G Ninja cd build cmake --build . ctest The output might look like this: Start 1: dlognormTest.DoubleInput 1/2 Test #1: dlognormTest.DoubleInput ......... Passed 0.11 sec Start 2: dlognormTest.IntInput 2/2 Test #2: dlognormTest.IntInput ............ Passed 0.11 sec 100% tests passed, 0 tests failed out of 2 Total Test time (real) = 0.25 sec Congratulations! You’ve successfully set up a test project and run a test binary using GoogleTest. Let’s use Google Benchmark to measure the real time and CPU time used for running the produced binary. 11.2.7 Benchmark template #include &quot;benchmark/benchmark.h&quot; #include &quot;../src/code.hpp&quot; void BM_FunctionName(benchmark::State&amp; state) { for (auto _ : state) // This code gets timed Function() } // Register the function as a benchmark BENCHMARK(BM_FunctionName); 11.2.8 Benchmark example We will continue using the dlognorm.hpp example. We can create a benchmark file dlognorm_benchmark.cpp and put it in the tests folder: #include &quot;benchmark/benchmark.h&quot; #include &quot;../src/dlognorm.hpp&quot; void BM_dlgnorm(benchmark::State&amp; state) { for (auto _ : state) dlognorm(5.0, 10.0, 2.5); } BENCHMARK(BM_dlgnorm); Please see more examples on Google Benchmark GitHub repository for a more comprehensive feature overview. 11.2.9 Add benchmarks to CMakeLists.txt and run the benchmark To build the code, add the following contents to the end of your CMakeLists.txt file: FetchContent_Declare( googlebenchmark URL https://github.com/google/benchmark/archive/refs/tags/v1.6.0.zip ) FetchContent_MakeAvailable(googlebenchmark) add_executable( dlognorm_benchmark dlognorm_benchmark.cpp ) target_include_directories( dlognorm_benchmark PUBLIC ${CMAKE_SOURCE_DIR}/../ ) target_link_libraries( dlognorm_benchmark benchmark_main ) To run the benchmark, cmake --build . ./dlognorm_benchmark.exe The output might look like this: Run on (8 X 2112 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) ***WARNING*** Library was built as DEBUG. Timings may be affected. ----------------------------------------------------- Benchmark Time CPU Iterations ----------------------------------------------------- BM_dlgnorm 153 ns 153 ns 4480000 11.3 R testing FIMS uses R testthat package for writing R tests. You can install the packages following the instructions on testthat website. If you are not familiar with testthat, the testing chapter in R packages gives a good overview of testing workflow, along with structure explanation and concrete examples. 11.3.1 R testthat template test_that(&quot;TestName&quot;, { ...test body... }) 11.4 Test case template and examples 11.4.1 Test case template Individual functional or integration test cases will be designed following the template below. Test ID. Create a meaningful name for the test case. Features to be tested. Provide a brief statement of test objectives and description of the features to be tested. (Identify the test items following the FIMS software design specification document and identify all features that will not be tested and the rationale for exclusion) Approach. Specify the approach that will ensure that the features are adequately tested and specify which type of test is used in this case. Evaluation criteria. Provide a list of expected results and acceptance criteria. Pass/fail criteria. Specify the criteria used to determine whether each feature has passed or failed testing. In addition to setting pass/fail criteria with specific tolerance values, a documentation that just views the outputs of some tests may be useful if the tests require additional computations, simulations, and comparisons Test deliverables. Identify all information that is to be delivered by the test activity. Test logs and automated status reports 11.4.2 Test case examples 11.4.2.1 General test case The test case below is a general case and it can be applied to many functions/modules. For individual functions/modules, please make detailed test cases for specific options to avoid duplication as much as possible. Test ID General test case Features to be tested The function/module returns correct output values given different input values The function/module returns error messages when users give wrong types of inputs The function/module notifies an error if the input value is outside the bound of the input parameter Approach Prepare expected true values using R Run tests in R using testthat and compare output values with expected values Push tests to the working repository and run tests using GitHub Actions Run tests in different OS environments (windows latest, macOS latest, and ubuntu latest) using GitHub Actions Submit pull request for code review Evaluation Criteria The tests pass if the output values equal to the expected true values The tests pass if the function/module returns error messages when users give wrong types of inputs The tests pass if the function/module returns error messages when user provides an input value that is outside the bound of the input parameter Test deliverables Test logs on GitHub Actions 11.4.2.2 Functional test example: TMB probability mass function of the multinomial distribution Test ID Probability mass function of the multinomial distribution Features to be tested Same as the general test case Approach Functional test Prepare expected true values using R function dmultinom from package ‘stats’ Evaluation Criteria Same as the general test case Test deliverables Same as the general test case 11.4.2.3 Integration test example: Li et al. 2021 age-structured stock assessment model comparison Test ID Age-structured stock assessment comparison (Li et al. 2021) Features to be tested Null case (update standard deviation of the log of recruitment from 0.2 to 0.5 based on Siegfried et al. 2016 snapper-grouper complex) Recruitment variability Stochastic Fishing mortality (F) F patterns (e.g., roller coaster: up then down and down then up; constant Flow, FMSY, and Fhigh) Selectivity patterns Recruitment bias adjustment Initial condition (unit of catch: number or weight) Model misspecification (e.g., growth, natural mortality, and steepness, catchability etc) Approach Integration test Prepare expected true values from an operating model using R functions from Age_Structured_Stock_Assessment_Model_Comparison GitHub repository Evaluation Criteria Summarize median absolute relative error (MARE) between true values from the operating model and the FIMS estimation model If all MAREs from the null case are less than 10% and all MARES are less than 15%, the tests pass. If the MAREs are greater than 15%, a closer examination is needed. Test deliverables In addition to the test logs on GitHub Actions, a document that includes comparison figures from various cases (e.g., Fig 5 and 6 from Li et al. 2021) will be automatically generated A table that shows median absolute relative errors in unfished recruitment, catchability, spawning stock biomass, recruitment, fishing mortality, and reference points (e.g., Table 6 from Li et al. 2021) will be automatically generated 11.4.2.4 simulation testing: challenges and solutions One thing that might be challenging for comparing simulation results is that changes to the order of different calls to simulation will change the simulated values and then tests may fail even though it is just because different random numbers are used or the order of the simulation changes through model development. Several solutions could be used to address the simulation testing issue. Please see discussions on the FIMS-planning issue page for details. Once we start developing simulation modules, there are two ways that help compare simulated data from FIMS and a test. Add a TRUE/FALSE parameter in each FIMS simulation module for setting up testing seed. When testing the module, use the parameter=TRUE to fix the seed number in R and conduct tests. If adding a TRUE/FALSE parameter does not work as expected, then carefully check simulated data from each component and make sure it is not a model coding error. FIMS will use set.seed() from R to set seed. “rstream” package will be investigated if one of the requirements of FIMS simulation module is to generate multiple streams of random numbers to associate distinct streams of random numbers with different sources of randomness. rstream was specifically designed to address the issue of needing very long streams of pseudo-random numbers for parallel computations. Please see rstream paper and RngStreams for more details. 11.5 Glossary 11.5.1 Unit testing Description: It tests individual methods and functions of the classes, components or modules used by the software independently. It executes only small portions of the test cases during the development process. Writer: Developer Advantages: It finds problems early and helps trace the bugs in the development cycle; cheap to automate when a method has clear input parameters and output; can be run quickly. Limitations: Tedious to create; it won’t catch integration errors if a method or a function has interactions with something external to the software. Examples: A recruitment module may consist of a few stock-recruit functions. We could use a set of unit test cases that ensure each stock-recruit function is correct and meets its design as intended while developing the function. Reference: Wikipedia description 11.5.2 Functional testing Description: It checks software’s performance with respect to its specified requirements. Testers do not need to examine the internal structure of the piece of software tested but just test a slice of functionality of the whole system after it has been developed. Writer: Tester Advantages: It verifies that the functionalities of the software are working as defined; lead to reduced developer bias since the tester has not been involved in the software’s development. Limitations: Need to create input data and determine output based on each function’s specifications; need to know how to compare actual and expected outputs and how to check whether the software works as the requirements specified. Examples: The software requires development of catch-based projection. We could use a set of functional test cases that help verify if the model produces correct output given specified catch input after catch-based projection has been implemented in the system. Reference: Wikipedia description; WHAM testthat examples 11.5.3 Integration testing Description: A group of software modules are coupled together and tested. Integrate software modules all together and verify the interfaces between modules against the software design. It is tested until the software works as a system. Writer: Tester Advantages: It builds a working version of the system by putting the modules together. It assembles a software system and helps detect errors associated with interfacing. Limitations: The tests only can be executed after all the modules are developed. It may be difficult to locate errors because all components are integrated together. Examples: After developing all the modules, we could set up a few stock assessment test models and check if the software can read the input file, run the stock assessment models, and provide desired output. Reference: Wikipedia description 11.5.4 Run-time testing Description: Checks added in the software that catch user input errors. The developer will add in checks to the software; the user will trigger these checks if there are input errors Writer: developer Advantages: Provides guidance to the user while using the software Limitations: Adding many checks can cause the software to run more slowly, the messages need to be helpful so the user can fix the input error. Examples: A user inputs a vector of values when they only need to input a single integer value. When running the software, they get an error message telling them that they should use a single integer value instead. Reference: Testing R code book 11.5.5 Regression testing Description: Re-running tests to ensure that previously developed and tested software still performs after a change. Testers can execute regression testing after adding a new feature to the software or whenever a previously discovered issue has been fixed. Testers can run all tests or a part of the test suite to check the correctness or quality of the software. Writer: Tester Advantages: It ensures that the changes made to the software have not affected the existing functionalities or correctness of the software. Limitations: If the team makes changes to the software often, it may be difficult to run all tests from the test suite frequently. In that case, it’s a good idea to have a regression testing schedule. For example, run a part of the test suite that is higher in priority after every change and run the full test suite weekly or monthly, etc. Examples: Set up a test suit like the ss-test-models repository. The test cases can be based on real stock assessment models, but may not be the final model version or may have been altered for testing purposes. Test the final software by running this set of models and seeing if the same results for key model quantities remain the same relative to a “reference run” (e.g., the last release of the software). Reference: Wikipedia description 11.5.6 Platform compatibility testing Description: It checks whether the software is capable of running on different operating systems and versions of other softwares. Testers need to define a set of environments or platforms the application is expected to work on. Testers can test the software on different operating systems or platforms and report the bugs. Writer: Tester Advantages: It ensures that the developed software works under different configurations and is compatible with the client’s environment. Limitations: Testers need to have knowledge of the testing environment and platforms to understand the expected software behavior under different configurations. It may be difficult to figure out why the software produces different results when using different operating systems. Examples: Set up an automated workflow and see if the software can be compatible with different operating systems, such as Windows, macOS, and Linux. Also, testers can check if the software is compatible with different versions of R (e.g., release version and version 3.6, etc). Reference: International Software Testing Qualification Board 11.5.7 Beta testing Description: It is a form of external user acceptance testing and the feedback from users can ensure the software has fewer bugs. The software is released to a limited end-users outside of the implementation team and the end-users (beta testers) can report issues of beta software to the implementation team after further testing. Writer: Members of implementation team and other users Advantages: It helps in uncovering unexpected errors that happen in the client’s environment. The implementation team can receive direct feedback from users before shipping the software to users. Limitations: The testing environment is not under the control of the implementation team and it may be hard to reproduce the bugs. Examples: Prepare a document that describes the new features of the software and share it with selected end-users. Send a pre-release of the software to selected users for further testing and gather feedback from users. Reference: Wikipedia description; SS prerelease example 11.5.8 One-off testing Description: It is for replicating and fixing user-reported bugs. It is a special testing that needs to be completed outside of the ordinary routine. Testers write a test that replicates the bug and run the test to check if the test is failing as expected. After fixing the bug, the testers can run the test again and check if the test is passing. Writer: Developer and tester Advantages: The test is simple, fast, and efficient for fixing bugs. Limitations: The tests are specific to bugs and may require manual testing. Examples: A bug is found in the code and the software does not work properly. Tester can create a test to replicate the bug and the test would fail as expected. After the developer fixes the bug, the tester can run the test and see if the issue is resolved. Reference: International Software Testing Qualification Board; SS bug fix example "],["documentation.html", "Chapter 12 Documentation 12.1 Writing function reference 12.2 Writing a vignette 12.3 Step by step documentation update process", " Chapter 12 Documentation In this section we will describe how to document your code. For more information about code documentation in general, please see the toolbox blog post here. This post describes the differences between the types of documentation, while below we give specific, brief instructions on developer responsibilities for FIMS. 12.1 Writing function reference Function reference can be written inline in comments above the function in either C++ or R. The tools you can use to generate reference from comments are called Doxygen and Roxygen in C++ and R respectively. Both can include LaTeX syntax to denote equations, and both use @ tags to name components of the function reference /** * @brief This function calculates the von Bertalanffy growth curve. * \\f$ * * length\\_at\\_age = lmin + (lmax - lmin)*\\frac{(1.0 - c^ {(age - a\\_min)}))}{(1.0 - c^{(a\\_max - a\\_min)})} * * \\f$ * * @param age * @param sex * @return length\\_at\\_age */ The only difference between syntax for R and C++ code is how comments are denoted in the language. #&#39; This function calculates the von Bertalanffy growth curve. #&#39; #&#39; @param age #&#39; @param sex #&#39; @return length_at_age You should, at minimum, include the tags @param, @return, and @examples in your function reference if it is an exported function. Functions that are only called internally do not require an @examples tag. Other useful tags include @seealso and @export for Roxygen chunks. 12.2 Writing a vignette If this is an exported function, a vignette can be a helpful tool to users to know how to use your function. For now, a rough approximation of the “get started” vignette is written in the software user guide page of this book. If you include a vignette for your function, you can link to it in the Roxygen documentation with the following code. #&#39; \\code{vignette(&quot;help&quot;, package = &quot;mypkg&quot;)} 12.3 Step by step documentation update process Write the function reference in either R or C++ as described above. Check the software user guide and check that any changes you have made to the code are reflected in the code snippets on that page. Push to the feature branch. Ensure that the documentation created by the automated workflow is correct and that any test cases execute successfully before merging into main. "],["glossary-1.html", "Glossary", " Glossary In this section we will define terms that come up throughout this handbook. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
