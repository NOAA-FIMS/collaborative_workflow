[["index.html", "FIMS Developer Handbook Chapter 1 Contributing to this book 1.1 Description 1.2 Edit and preview book changes", " FIMS Developer Handbook FIMS Implementation Team 2024-09-20 Chapter 1 Contributing to this book This is a book written in Markdown describing the FIMS development workflow for FIMS developers and contributors. It is intended as a living document and will change over time as the FIMS project matures. Some sections may be incomplete or missing entirely. Suggestions or contributions may be made via the FIMS collaborative workflow github site https://github.com/NOAA-FIMS/collaborative_workflow. This section describes how to edit and contribute to the book. 1.1 Description Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one or more chapters. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Edit and preview book changes When you want to make a change to this book, follow the below steps: 1. Create a new feature branch either from the issue requesting the change or from the repo on Github. 2. Pull the remote branch into your local branch and make your changes to the .Rmd files locally. 3. When you are done editing, do not render the book locally, but push your changes to the remote feature branch. 4. Pushing to the remote feature branch initiates a Github action that creates a .zip file you should download and unzip. Open the file index.html in a browser to preview the rendered .html content. If the action fails, this means the bookdown could not be rendered. Use the Github action log to determine what the problem is. 5. When the book can be rendered and you are satisfied with the changes, submit a pull request to merge the feature branch into main. "],["code-of-conduct.html", "Chapter 2 Code of conduct 2.1 FIMS contributor conduct 2.2 Our pledge 2.3 Our standards 2.4 Enforcement responsibilities 2.5 Scope 2.6 Enforcement 2.7 Enforcement guidelines 2.8 Supporting good conduct 2.9 Attribution", " Chapter 2 Code of conduct 2.1 FIMS contributor conduct 2.2 Our pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. 2.3 Our standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others’ private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting 2.4 Enforcement responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. 2.5 Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. 2.6 Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement anonymously using this form. Reports will be reviewed by a member of the NOAA Fisheries Office of Science and Technology who is not participating in the FIMS Project [Patrick Lynch] but has the full support of FIMS Community Leaders. All reports will be reviewed promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident whenever possible; however, please note behaviors that meet the official criteria for harrassment must be reported by supervisors under NOAA policy. 2.7 Enforcement guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 2.7.1 1. Correction Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2.7.2 2. Warning Community Impact: A violation through a single incident or series of actions. Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 2.7.3 3. Temporary ban Community Impact: A serious violation of community standards, including sustained inappropriate behavior. Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 2.7.4 4. Permanent ban Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence: A permanent ban from any sort of public interaction within the community. 2.8 Supporting good conduct FIMS Community leaders will create default community health files (e.g. CONTRIBUTING, CODE_OF_CONDUCT) to be used in all repositories owned by FIMS. 2.9 Attribution This Code of Conduct is copied from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder. For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations. "],["fims-project-management-process.html", "Chapter 3 FIMS project management process 3.1 FIMS governance 3.2 FIMS development cycle", " Chapter 3 FIMS project management process 3.1 FIMS governance The FIMS Terms of Reference describes the high level organization of the FIMS Project. Additional details on roles and responsibilities are provided here. 3.1.1 Developers Developers are expected to adhere to the principles and guidelines outlined within this handbook, including the Code of Conduct, Contributer Guidelines, Style Guide, Issue Tracking, and Testing. 3.1.2 C++ developers The C++ developer responsibilities include: Writing the module code. Creating documentation for the module and building the documentation in doxygen to ensure it is error-free. Run cmake --build build and review generated doxygen HTMLs locally to ensure they are error-free. Implementing the suite of required test cases in Google Test for the module. Run cmake --build build and ctest --test-dir build locally and make sure the C++ tests pass before pushing tests to remote feature branch. If there are failing tests, run ctest --test-dir --rerun-failed --output-on-failure to re-run the failed tests verbosely. Ensuring the run-clang-tidy and run-googletest Github Actions workflows pass on the remote feature branch Below is a list of online resources for learning C++: * cplusplus.com * docs.microsoft.com * geeksforgeeks.org * learncpp.com * positioniseverything.net * w3schools.com/cpp 3.1.3 R developers The R developers responsibilities include: Writing the Rcpp interface to the C++ code. Writing Roxygen documentation for any R functions. Run devtools::document() locally and before pushing changes to the remote branch. Writing testthat() test cases for any R functionality Run devtools::test() locally before pushing tests to the remote feature branch. Running styler::style_pkg() to style R code locally and then push changes to remote feature branch. If there are many changes, please do this in a separate commit. Running devtools::check() locally and make sure the package can be compiled and R tests pass. If there are failing tests, run devtools::test(filter = \"file_name\") (where “test-file_name.R” is the testthat file containing failing tests) and edit code/tests to troubleshoot tests. During development, run devtools::build() locally to build the package more frequently and faster. Ensuring the code passes the call-r-cmd-check GitHub Action workflow on the remote feature branch. 3.1.4 All developers Once these are complete, the developer should create a pull request according to the correct template and assign the issue tracking the completion of the bug fix and/or feature to the assigned review team. The developer must resolve any issues arising from the review and get confirmation from the review team before the pull request is merged into the upstream branch. 3.1.5 Project Lead The Project Lead is responsible for driving decisions on FIMS features, user interfaces, and project guidelines and standards based on the vision and objectives of FIMS and discussions with the OST development team and regional product representatives. The project lead ensures the FIMS product satisfies user and business requirements, incorporates feedback, and iterates on the design and development as needed. The Project Lead will triage issues and pull requests weekly and ensure development and code review occur in a timely manner and according to project guidelines, priorities, and standards. The Project Lead is also responsible for communicating project status via maintenance of the Github projects and scheduling tasks and managing change requests. 3.1.6 Lead Software Architect The Lead Software Architect is responsible for advising the design of designing the FIMS product architecture to maximize portability and extensibility, managing technical risks and opportunities, mentoring development and implementation team members, advising the project lead on software design, refactor, and implementation decisions, scheduling of tasks, managing change requests, and guaranteeing quality of deliveries via code review. The Lead Software Architect also educates the team on technical best practices. 3.1.7 Lead Test Engineer The Lead Test Engineer is responsible for designing and driving test objectives, test strategies, and test plans of the FIMS product at subsequent milestones. The Lead Test Engineer will identify the tools for test reporting, management and automation, guide and monitor the design, implementation, and execution of test cases and test procedures. The Lead Test Engineer will train and mentor implementation team members on how to effectively write and debug tests. 3.1.8 Lead Statistical Computing Engineer The Lead Statistical Computing Engineer is responsible for designing the FIMS statistical architecture that maximizes statistical accuracy and ensures the implementation of statistical good practices. The Lead Statistical Computing Engineer will advise the Project Lead on design and implementation decisions and will work closely with the Lead Software Architect to ensure a balance between computation and statistical efficiency, and with the Lead Test Engineer to develop tests that check the statistical accuracy of model design. 3.1.9 Outreach and Transition Coordinator The Outreach and Transition Coordinator communicates with policy-makers, NOAA leadership, and regional offices on transition plans from existing assessment models and processes to FIMS. This coordinator works with academic partners to develop and coordinate training on using FIMS. 3.1.10 Lead of Workflows, Accessibility, and Integration The Lead of Workflows, Accessibility, and Integration is responsible for designing and driving workflows and automation to support the reliability and robustness of the FIMS. The Lead of Workflows, Accessibility, and Integration ensures FIMS aligns with expected standards for accessibility and quality control in accordance with guidelines set by the Fisheries Integrated Toolbox. This lead coordinates with the Lead Test Engineer to ensure test cases are automated and successfully run by GitHub Actions and coordinates with the Lead Statistical Computing Engineer to identify opportunities to expand FIMS across related disciplines. 3.1.11 Regional representatives Regional representatives are expected to assist in FIMS implementation through design, development, and testing of FIMS. They also communicate FIMS progress and design to their respective regions and teammates. Representatives serve as power users who provide basic training and outreach within their centers on transitioning to FIMS. These representatives are also responsible for relaying feedback, questions, and training requests that they cannot complete back to the NSAP development team and Project Lead. Regional representatives are expected to introduce their partner fishery management organizations to FIMS to assist transition of FIMS from research to operations. 3.1.12 Code of conduct enforcement The code of conduct enforcer is responsible for responding to allegations of code of conduct violations in an appropriate manner. This could include a conversation with the violator, his or her manager, up to and including expulsion from the FIMS development team. If the violator is an external collaborator, they can be banned from contributing to the FIMS Github resources in the future. 3.1.13 External collaborators External collaborators interested in contributing to FIMS development are required to clone or fork the FIMS repository, make changes, and submit a pull request. However, collaborators are strongly encouraged to submit an issue via the main FIMS repository for discussion prior to development. In general, forks are discouraged for development that is intended for integration into FIMS as it becomes difficult to keep track of multiple forks. If collaborators wish to use FIMS as a starting-point for a brand new project that they do not intend to merge back into the main branch, they can start a fork. However, if they intend to create a pull request, they should clone the repository and use a branch. Pull requests from forks will be reviewed the same as a pull request submitted from a branch. Users will need to conform to the same standards and all contributions must pass the standard tests as well as provide tests that check the new feature. 3.2 FIMS development cycle FIMS is structured as an agile software development process with live development on the web and Github. The development process cycles through a planning, analysis, and design phase leading to the establishment of a developmental Milestone. The implementation phase is made up of several development sprints that meet the objectives of the established Milestone. This is followed by testing &amp; integration and a maintenance phase before the cycle starts over again. FIMS is currently in the implementation phase of Milestone 1. See M1 model specification for a description of the model. Figure 3.1: FIMS Development Cycle. Current development stage is the implementation phase of Milestone 1 3.2.1 Issue lifecycle FIMS development will adhere to a lifecycle for issues that makes it clear which issues can be resolved when. Creation — The event that marks the creation of an issue. An issue is not Active when it is Created. Issues that are opened are assigned to the FIMS Project Lead with the label: needs-triage. A issue is not considered Active until this label is removed. * Activation — When the needs-triage label is removed and the issue is assigned to a developer, the issue becomes Active. This event happens once in the lifecycle of an issue. Activation usually is not undone but it can be undone if an issue needs additional discussion; in this case, the needs-triage label is applied again. An issue is Active from the time it is Activated until reaches Resolution. * Response — This event only happens if the triage team deems an issue to a wont-fix or delayed. This requires communication with the party who opened the issue as to why this will not be addressed or will be moved to a later milestone. Resolution — The event that marks the resolution of an issue. This event happens once in the lifetime of an issue. This event can be undone if an issue transitions from a resolved status to an unresolved status, in which case the system considers the issue as never had been resolved. A resolution involves a code check-in and pull request, at which point someone must review and approve the pull request before the issue can transition states. In Review - The issue is “in review” after a code solution has been proposed and is being considered via a pull request. If this is approved, the issue can move into the “Closed” state. * Closure—The event that marks the closure of an Issue. This even happens once in the lifetime of an issue. The issue can enter the Closed state from either the “In Review” or “Response” state. Figure 3.2: Flow chart that describes above process visually, e.g., how an issue moves from creation, to activation, to response or resolution, and is finally closed. 3.2.2 M2 development workflow 3.2.3 Feature validation FIMS uses a standardized set of criteria to prioritize and determine which features will be incorporated into the next development milestone. TODO: add criteria (to be defined) used to prioritize features for future milestones "],["m1-model-specification.html", "Chapter 4 M1 model specification 4.1 Inherited functors from TMB 4.2 Beverton-Holt recruitment function 4.3 Logistic function with extensions 4.4 Catch and fishing mortality 4.5 Modeling loops 4.6 Expected numbers and quantities 4.7 Initial values 4.8 Likelihood calculations 4.9 Statistical Inference:", " Chapter 4 M1 model specification This section describes the implementation of the modules in FIMS in milestone 1. For the first milestone, we implemented enough complexity to adequately test a very standard population model. For this reason, we implemented the minimum structure that can run the model described in Li et al. 2021. The FIMS at the end of milestone 1 is an age-structured integrated assessment model with two fleets (one survey, one fishery) and two sexes. 4.1 Inherited functors from TMB 4.1.1 Atomic functions Wherever possible, FIMS avoids reinginvent atomic functions with extant definitions in TMB. If there is a need for a new atomic function the development team can add it to TMB using the TMB_ATOMIC_VECTOR_FUNCTION() macro following the instructions here. Prototype atomic functions under development for future FIMS milestones are stored in the fims_math.hpp file in the m1-prototypes repository. 4.1.2 Statistical distributions All of the statistical distributions needed for the first milestone of FIMS are implemented in TMB and need not be replicated. Code can be found here. Distribution Name FIMS wrapper Normal dnorm FIMS code Multinomial dmultinom FIMS code Lognormal uses dnorm FIMS code 4.1.2.1 Normal Distribution \\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\mathrm{exp}\\Bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2} \\Bigg),\\] where \\(\\mu\\) is the mean of the distribution and \\(\\sigma^2\\) is the variance. 4.1.2.2 Multinomial Distribution For \\(k\\) categories and sample size, \\(n\\), \\[f(\\underline{y}) = \\frac{n!}{y_{1}!... y_{k}!}p^{y_{1}}_{1}...p^{y_{k}}_{k},\\] where \\(\\sum^{k}_{i=1}y_{i} = n\\), \\(p_{i} &gt; 0\\), and \\(\\sum^{k}_{i=1}p_{i} = 1\\). The mean and variance of \\(y_{i}\\) are respectively: \\(\\mu_{i} = np_{i}\\), \\(\\sigma^{2}_{i} = np_{i}(1-p_{i})\\) 4.1.2.3 Lognormal Distribution \\[f(x) = \\frac{1.0}{ x\\sigma\\sqrt{2\\pi} }\\mathrm{exp}\\Bigg(-\\frac{(\\mathrm{ln}(x) - \\mu)^{2}}{2\\sigma^{2}}\\Bigg),\\] where \\(\\mu\\) is the mean of the distribution of \\(\\mathrm{ln(x)}\\) and \\(\\sigma^2\\) is the variance of \\(\\mathrm{ln}(x)\\). 4.2 Beverton-Holt recruitment function For parity with existing stock assessment models, the first recruitment option in FIMS is the steepness parameterization of the Beverton-Holt model (Beverton and Holt, 1957), \\[R_t(S_{t-1}) =\\frac{0.8R_0hS_{t-1}}{0.2R_0\\phi_0(1-h) + S_{t-1}(h-0.2)}\\] where \\(R_t\\) and \\(S_t\\) are mean recruitment and spawning biomass at time \\(t\\), \\(h\\) is steepness, and \\(\\phi_0\\) is the unfished spawning biomass per recruit. The initial FIMS model implements a static spawning biomass-per-recruit function, with the ability to overload the method in the future to allow for time-variation in spawning biomass per recruit that results from variation in life-history characteristics (e.g., natural mortality, maturity, or weight-at-age). Recruitment deviations (\\(r_t\\)) are assumed to be normally distributed in log space with standard deviation \\(\\sigma_R\\), \\[r_t \\sim N(0,\\sigma_R^2)\\] Because \\(r_t\\) are applied as multiplicative, lognormal deviations, predictions of realized recruitment include a term for bias correction (\\(\\sigma^2_R/2\\)). However, true \\(r_t\\) values are not known, but rather estimated (\\(\\hat{r}_t\\)), and thus the bias correction applies an adjustment factor, \\(b_t=\\frac{E[SD(\\hat{r}_{t})]^2}{\\sigma_R^2}\\) (Methot and Taylor, 2011). The adjusted bias correction, mean recruitment, and recruitment deviations are then used to compute realized recruitment (\\(R^*_t\\)), \\[R^*_t=R_t\\cdot\\mathrm{exp}\\Bigg(\\hat{r}_{t}-b_t\\frac{\\sigma_R^2}{2}\\Bigg)\\] The recruitment function should take as input the values of \\(S_t\\), \\(h\\), \\(R_0\\), \\(\\phi_0\\), \\(\\sigma_R\\), and \\(\\hat{r}_{t}\\), and return mean-unbiased (\\(R_t\\)) and realized (\\(R^*_t\\)) recruitment. 4.3 Logistic function with extensions \\[y_i=\\frac{1}{1+\\mathrm{exp}(-s \\cdot(x_i-\\nu))}\\] Where \\(y_i\\) is the quantity of interest (proportion mature, selected, etc.), \\(x_i\\) is the index (can be age or size or any other quantity), \\(\\nu\\) is the median (inflection point), and \\(s\\) is the slope parameter from an alternative parameterization. Logistic functions for maturity and selectivity should inherit and extend upon the base logistic function implementation. The parameterization for the double logistic curve is specified as \\[y_i=\\frac{1.0}{ 1.0 + \\mathrm{exp}(-1.0 \\cdot s_1(x_i - \\nu_1))} \\left(1-\\frac{1.0}{ 1.0 + \\mathrm{exp}(-1.0 \\cdot s_2 (x_i - \\nu_2))} \\right)\\] Where \\(s_1\\) and and \\(\\nu_1\\) are the slope and median (50%) parameters for the ascending limb of the curve, and \\(s_2\\) and and \\(\\nu_2\\) are the slope and median parameters for the descending limb of the curve. This is currently only implemented for the selectivity module. 4.4 Catch and fishing mortality The Baranov catch equation relates catch to instantaneous fishing and natural mortality. \\[ C_{f,a,t}=\\frac{F_{f,a,t}}{F_{f,a,t}+M}\\Bigg[1-\\mathrm{exp}(-F_{f,a,t}-M)\\Bigg]N_{a,t}\\] Where \\(C_{f,a,t}\\) is the catch at age \\(a\\) at time \\(t\\) for fleet \\(f\\), \\(F_t\\) is instantaneous fishing mortality, \\(M\\) is assumed constant over ages and time in the minimum viable assessment model, \\(N_{a,t}\\) is the number of age \\(a\\) fish at time \\(t\\). \\[F_{f,a,t}=\\sum_{a=0}^A s_{f,a}F_t\\] \\(s_{f,a}\\) is selectivity at age \\(a\\) for fleet \\(f\\). Selectivity-at-age is constant over time. Catch is in metric tons and survey is in number, so calculating catch weight (\\(CW_t\\)) is done as follows: \\[ CW_t=\\sum_{a=0}^A C_{a,t}w_a \\] Survey numbers are calculated as follows \\[I_t=q_t\\sum_{a=0}^AN_{a,t}\\] Where \\(I_t\\) is the survey index and \\(q_t\\) is survey catchability at time \\(t\\). 4.5 Modeling loops This tier associates the expected values for each population section associated with a data source to that data source using a likelihood function. These likelihood functions are then combined into an objective function that is passed to TMB. The population loop is initialized at a user-specified age, time increment, and seasonal structure, rather than assuming ages, years, or seasons follow any pre-defined structure. Population categories will be described flexibly, such that subpopulations such as unique sexes, stocks, species, or areas can be handled identically to reduce duplication. Each subpopulation will have a unique set of attributes assigned to it, such that each subpopulation can share or have a different functional process (e.g., recruitment function, size-at-age) than a different category. Spawning time and recruitment time are user-specified and can occur more than once per year. For the purposes of replicating model comparison project outputs, in milestone 1, all processes including spawning and recruitment occur January 1, but these should be specified via the spawn_time and recruit_time inputs into FIMS to allow for future flexibility. Spawning and recruitment timing can be input as a scalar or vector to account for multiple options. Within the population loop, matrices denoting population properties at different partitions (age, season, sex) are translated into a single, dimension-folded index. A lookup table is computed at model start so that the dimension-folded index can be mapped to its corresponding population partition or time partition (e.g., population(sex, area, age, species, time, …)) so the programmer can understand what is happening. The model steps through each specified timestep to match the data to expected values, and population processes occur in the closest specified timestep to the user-input process timing (e.g., recruitment) across a small timestep that is a predefined constant. 4.6 Expected numbers and quantities The expected values are calculated as follows in the population.hpp file: \\[ B_t=\\sum_{a=0}^AN_{a,t}w_a\\] where \\(B_t\\) is total biomass in time \\(t\\), \\(N\\) is total numbers, \\(w_a\\) is weight-at-age \\(a\\) in kilograms. \\[N_t=\\sum_{a=0}^AN_{a,t}\\] where \\(N_at\\) is the total number of fish at age \\(a\\) in time \\(t\\). \\[UnfishedNAA_{t,0} = R0_{t}\\] Annual unfished numbers at age and unfished spawning biomass are tracked in the model assuming annual recruitment at rzero and only natural mortality. This provides a dynamic reference point that accounts for time varying rzero and M. This does not currently include recruitment deviations. \\[UnfishedNAA_{t,0} = R0_{t}\\] \\[UnfishedNAA_{t,a} = UnfishedNAA_{t-1,a-1}exp(-M_{t-1,a-1})\\] for all t&gt;0 and numbers at age at the start of the first year are model parameter inputs. \\[ UnfishedSSB_t=\\sum_{a=0}^AUnfishedNAA_{a,t}w_aFracFemale_aFracMature_a\\] All spawning stock biomass values are current calculated at January 1 each year. This will be updated in future milestones. 4.7 Initial values The initial equilibrium recruitment (\\(R_{eq}\\)) is calculated as follows: \\[R_{eq} = \\frac{R_{0}(4h\\phi_{F} - (1-h)\\phi_{0})}{(5h-1)\\phi_{F}} \\] where \\(\\phi_{F}\\) is the initial spawning biomass per recruitment given the initial fishing mortality \\(F\\). The initial population structure at the start of the first model year is input as an estimated parameter vector of numbers at age. This allows maximum flexibility for the model to estimate non-equilibrium starting conditions. Future milestones could add an option to input a single F value used to calculate an equilibrium starting structure. 4.8 Likelihood calculations Age composition likelihood links proportions at age from data to model using a multinomial likelihood function. The multinomial and lognormal distributions, including atomic functions are provided within TMB. Survey index likelihood links estimated CPUE to input data CPUE in biomass using a lognormal distribution. (model.hpp) Catch index likelihood links estimated catch to input data catch in biomass using a lognormal distribution. (model.hpp) Age composition likelihoods link catch-at-age to expected catch-at-age using a multinomial distribution. Recruitment deviations control the difference between expected and realized recruitment, and they follow a lognormal distribution. (recruitment_base.hpp) 4.9 Statistical Inference: TODO: Add description detailing the statistical inference used in M1 "],["user-guide.html", "Chapter 5 User guide 5.1 Installing the package from R universe 5.2 Running FIMS", " Chapter 5 User guide This section details installation guides for users. For developers, see the developer installation guide. 5.1 Installing the package from R universe The following software is required: - R version 4.0.0 or newer Install the latest precompiled version FIMS from R universe within R: install.packages(&quot;FIMS&quot;, repos = c(&quot;https://noaa-fims.r-universe.dev&quot;, &quot;https://cloud.r-project.org&quot;)) 5.2 Running FIMS See the Introducing FIMS vignette. "],["developer-software-and-installation-guide.html", "Chapter 6 Developer Software and Installation Guide 6.1 Codespaces as an alternative to installing software 6.2 Software to install 6.3 Installing FIMS 6.4 Getting Help", " Chapter 6 Developer Software and Installation Guide This section describes the software you will need to contribute to this project as well as ways FIMS can be installed. 6.1 Codespaces as an alternative to installing software An alternative to setting up this software locally is using GitHub Codespaces. The FIMS repository already has a file to set up all of the needed software, so there is no need to install anything locally. To start a codespace on the FIMS repository, follow the GitHub documentation for creating a Codespace. 6.2 Software to install 6.2.1 git To contribute to the code, you will need git installed locally, and you may prefer to use an additional git GUI client such as GitHub Desktop. See the section on RStudio and VS Code for setting up those editors to work with git. To install git, please contact your IT department or follow the operating-system specific instructions available in the git documentation. 6.2.2 Development environment An integrated development environment (IDE) is recommended to organize code files, outputs, and build and debug environments. The most popular IDEs used by the development team are RStudio and Visual Studio (VS) Code. You are welcome to use any IDE or text-editor based workflow. 6.2.2.1 VS Code Install VS Code and configure it for using R and C++. For those migrating from RStudio to VS Code, this post on migrating to VS code may be helpful. You can also search the VS Code marketplace for additional keymap packages that import key mappings from commonly used text editors (e.g., Sublime, Notepad++, atom, etc.). A number of optional settings can be added to the user settings (settings.json) file in VS Code to improve the usability of R in VS Code. For example, the settings for interacting with R terminals can be adjusted. Additional settings for R are available in the extension wiki and shortcuts wiki. The keybindings.json and settings.json can be copied from one computer to another but the settings.json location differs depending on the operating system. Below are some example settings you may want to specify. { // Associate .RMD files with markdown: &quot;files.associations&quot;: { &quot;*.Rmd&quot;: &quot;markdown&quot;, }, // A cmake setting &quot;cmake.configureOnOpen&quot;: true, // Set where the rulers are, needed for Rewrap. 72 is the default we have // decided on for FIMS repositories.z &quot;editor.rulers&quot;: [ 72 ], // Should the editor suggest inline edits? &quot;editor.inlineSuggest.enabled&quot;: true, // Settings for github copilot and which languages to use it with or not. &quot;github.copilot.enable&quot;: { &quot;*&quot;: true, &quot;yaml&quot;: false, &quot;plaintext&quot;: false, &quot;markdown&quot;: false, &quot;latex&quot;: false, &quot;r&quot;: false }, // Setting for sending R code from the editor to the terminal &quot;r.alwaysUseActiveTerminal&quot;: true, // Needed to send large chunks of code to the r terminal when using radian &quot;r.bracketedPaste&quot;: true, // Needed to use httpgd for plotting in vscode &quot;r.plot.useHttpgd&quot;: true, // path to the r terminal (in this case, radian). Necessary to get the terminal to use radian. &quot;r.rterm.windows&quot;: &quot;C://Users//my.name//AppData//Local//Programs//Python//Python310//Scripts//radian.exe&quot;, //Use this only for Windows // options for the r terminal &quot;r.rterm.option&quot;: [ &quot;--no-save&quot;, &quot;--no-restore&quot;, &quot;max.print=500&quot; ], // Setting for whether to allow linting of documents or not &quot;r.lsp.diagnostics&quot;: true, // When looking at diffs under the version control tab, should whitspace be ignored? &quot;diffEditor.ignoreTrimWhitespace&quot;: false, // What is the max number of lines that are printed as output to the terminal? &quot;terminal.integrated.scrollback&quot;: 10000 } Other helpful extensions for VS Code are available in the VScode marketplace, e.g., - Github Copilot: An AI tool that helps with line completion. - Live Share: Collaborate on the same file remotely with other developers. - Rewrap: Helps rewrapping comments and text lines at a specified character count. Note that to get it working it will be necessary to add rulers. - GitLens (or GitLess): Adds more Git functionality. Some of the GitLens functionality is not free, and GitLess is a fork before the addition of these premium features. - A list of extensions that can help make VS Code operate more like RStudio is available by typing `R: Launch Rstudio Addin’ in the command pallete. 6.2.2.2 RStudio Install RStudio and configure it for working with git if you would like following these instructions. 6.2.3 C++ compiler Install a C++ compiler that supports the version of C++ being used in FIMS (e.g., gcc 5.0+, clang 5.0+, or MSVC 2015+). You can find the current version of C++ needed by searching for CMAKE_CXX_STANDARD in the CMakeLists.txt file in FIMS. For macOS users, Xcode 9.3+ provides clang 5.0. For Windows users, rtools4 includes gcc. To ensure the C++ compiler is on your path, open a command prompt and type gcc. If you get the following message, you are all set: gcc gcc: fatal error: no input files compilation terminated. If not, you will need to add the compiler is in your path by editing the environment variables for your account. In bash you can find out where a program in your path is located by running which &lt;binaryName&gt; replacing the carrots and everything inside of them with the binary name of interest. On Windows, you can push the Windows key, or the search tool next to the Windows Menu, and type env, which will bring up Edit environment variables for your account'. Then selectPath’ and New'. Add the path, e.g.,C:_64-w64-mingw32.static.posix. Close out of this and the previous window and then restart the terminal and R. On linux or mac, the easiset way to fix path issues is to move executables to a folder already in your path. To find existing path folders typeecho $PATH` in the terminal and hit enter and then move the binary to this path, e.g., sudo cp ~/Downloads/ninja /usr/bin/ Note that in certain Fisheries centers, NOAA employees do not have administrative privileges enabled to edit the local environmental path. In this situation it is necessary to create a ticket with IT to add cmake and ninja to your PATH on Windows. Also note that, for linux and mac users, you may need to add executable permissions to the binary after downloading it. You can do that by switching the terminal to the folder where you placed the binary and running the following command, where the example is for the ninja binary: sudo chmod +x ninja 6.2.4 GoogleTest You will need to install a build system such as CMake and a compatible build tool such as Ninja, which are both approved by NMFS HQ. Download the latest version of [CMake(https://cmake.org/download/). Where, Windows users will want cmake-*.*.*-windows-x86_64.zip and users of other platforms can choose the download that best suites their system. Place the unzipped folder in Documents\\Apps or another preferred folder. Download the latest version of ninja for your operating system (e.g., ninja-win.zip) and unzip the application in Documents\\Apps or another preferred folder. Open a new Command Prompt and type cmake. If you see details of usage, cmake is already in your PATH. Now type ninja. If you see a message that starts with ninja:, even if it is an error about not finding build.ninja, this means that ninja is already in your PATH. If either of the previous fail, follow the the instructions in the C++ section on how to add locations to your PATH. For linux and mac users you may also have to edit the permissions of the binary, see the C++ section for instructions. 6.2.5 GDB debugger Windows users who use GoogleTest may need GDB debugger to see what is going on inside of the program while it executes, or what the program is doing at the moment it crashed. rtools44 includes the GDB debugger in /rtools44/mingw64/bin/gdb.exe. See R on Windows FAQ for how to install it and the C++ section for how to add it to your path. 6.2.6 Doxygen Doxygen is required to build the C++ documentation for FIMS, which automates the generation of documentation from source code comments. To install Doxygen, please follow the instructions in the Doxygen manual. Visit the download page for the 64-bit zip for Windows and tar files for other operating systems. Unzip the download into Documents\\Apps\\Doxygen or another preferred folder and ensure the location is in your path. 6.2.7 R The following is needed: - The version of R specified in the DESCRIPTION file or newer (or RStudio version 1.2.5042 or newer) - The version of TMB specified in the DESCRIPTION file or newer - Windows users will need Rtools 6.3 Installing FIMS 6.3.1 Clone and build Cloning FIMS and building it is a good option if you intend to modify files in FIMS and want to test them out. - Clone the FIMS repository from the terminal via git clone https://github.com/NOAA-FIMS/FIMS.git. - Build FIMS within R using devtools::load_all(), which mimics package building, or devtools::install(), which actually builds the package from local files. 6.3.2 Precompiled Download from R universe within R using install.packages(\"FIMS\", repos = c(\"https://noaa-fims.r-universe.dev\", \"https://cloud.r-project.org\")). Install from GitHub within R using devtools::install_github(\"NOAA-FIMS/FIMS) to compile yourself, which allows you to be more specific about which version of the code is being built (e.g., you can refer to a tag or branch, which is not possible with the R universe install). 6.3.3 Fixing Fatal Error Windows users can expect to see some derivative of the following error message in their R session if they have not yet set some flags using {withr}. Fatal error: can&#39;t write &lt;xxx&gt; bytes to section .text of FIMS.o: &#39;file too big You can easily fix this by running the following line in your local R session. This call will need to be repeated each time you open a new session. withr::local_options(pkg.build_extra_flags = FALSE) This fix does not work when devtools::test() is called and FIMS is re-compiled. The call to devtools::test() in this case overwrites the local options set by {withr}. Compile FIMS first using devtools::load_all() before running devtools::test(). This fix removes the debugger flag -O0 -g from being automatically inserted for certain devtools calls (e.g. devtools::load_all()). Windows developers wanting to compile FIMS with the debugger turned on will need to run the above script in addition to manually modifying the call to PKG_CXXFLAGS in the Makevars.win file in src to the following: PKG_CXXFLAGS = -DTMB_MODEL -DTMB_EIGEN_DISABLE_WARNINGS -O1 -g To turn off the debugger flag, remove the -O1 -g flag: PKG_CXXFLAGS = -DTMB_MODEL -DTMB_EIGEN_DISABLE_WARNINGS 6.4 Getting Help Please report bugs along with a minimal reproducible example on GitHub Issues. "],["contributor-guidelines.html", "Chapter 7 Contributor Guidelines 7.1 Code 7.2 GitHub Collaborative Environment 7.3 git", " Chapter 7 Contributor Guidelines External contributions and feedback are important to the development and future maintenance of FIMS and are welcome. This section provides contributing guidelines and workflows for developers of FIMS and the ecosystem surrounding FIMS. All contributors, both internal and external, are required to abide by the Code of Conduct. 7.1 Code 7.1.1 Style Guide Style guides are used to ensure the code is consistent, easy to use (e.g., read, share, and verify) and ultimately easier to write. 7.1.1.1 C++ We use the Google C++ Style Guide for C++ code. 7.1.1.2 R We use the tidyverse style guide for R code. 7.1.1.3 Naming Conventions We use typename instead of class when defining templates for consistency with the TMB package. While types may be defined in many ways, we use Type instead of T to define Types within FIMS. 7.1.1.4 Commit Messages Commit messages communicate details about changes that have occurred to collaborators and improve team efficiency. The best guidance for how to create an excellent commit message can be found on Conventional Commits, which is our style guide for commit messages. 7.1.2 Coding Good Practices Following good software development and coding practices simplifies collaboration, improves readability, and streamlines testing and review. The following are industry-accepted standards: Adhere to the adopted Style Guides Avoid rework - take the time to check for existing options (e.g., in-house, open source, etc.) before writing code Keep code as simple as possible Use meaningful variable names that are easy to understand and clearly represent the data they store Use descriptive titles and consistent conventions for class and function names Use consistent names for temporary variables that have the same kind of role Add clear and concise coding comments Use consistent formatting and indentation to improve readability and organization Group code into separate blocks for individual tasks Avoid hard-coded values to ensure portability of code Follow the “Don’t Repeat Yourself” (DRY) principle for coding Avoid deep nesting Limit line length (wrap ~72 characters) of code but use a single line per paragraph in this markdown document Capitalize SQL queries so they are readily distinguishable from table/column names 7.2 GitHub Collaborative Environment Communication is managed via the NOAA-FIMS GitHub organization. 7.2.1 GitHub Issues GitHub Issues are key to keeping everyone informed and prioritizing tasks. All bugs, future projects, ideas, concerns, developments, etc. must be documented using an issue the appropriate repository’s Issue Tracker within the NOAA-FIMS organization, e.g., Issue Tracker for NOAA-FIMS/FIMS, before the code is altered. Issues are automatically tagged with the status: triage_needed tag and placed on the Issue Triage Board where they will be labeled, given an assignee, and given a milestone by those in charge of the triage process. There are different types of issues, e.g., bug, enhancement, etc., that might be applicable to your situation. Please read the descriptions for each issue type available and use the form that best suits your situation. The available types are the same or similar on each GitHub Issue page within the NOAA-FIMS organization. Navigate to the GitHub Issue page for NOAA-FIMS/FIMS to see the available types. 7.2.1.1 GitHub Issue Labels Labels help categorize and manage the work ahead of us. Members of the NOAA-FIMS organization can add labels to their issues upon submission of the issue. Additional labels will be applied during the triage process if needed. Labels within NOAA-FIMS are categorized, e.g., status: triage_needed is a status label. Typically, every issue should have one label per category. 7.2.1.2 GitHub Issue Templates The templates for issue types are maintained in the .github/ISSUE_TEMPLATE folder within the NOAA-FIMS/.github repository, which allows the same forms to be available in each repository without copying and pasting the code to each repositories .github/ISSUE_TEMPLATE folder. Additional examples of Example templates for issues and pull requests can be found on GitHub Docs. 7.2.1.3 GitHub Projects GitHub Projects are used to keep track and prioritize issues. There are several GitHub Projects for NOAA-FIMS such as the Issue Triage Board. 7.2.2 GitHub Cloning Any repository within NOAA-FIMS can be cloned to a personal or virtual machine. But, contributors without write access will need to fork the repository and then clone their fork. 7.2.3 GitHub Branching After cloning and before any work is done, ideas for potential changes to the code should be proposed in a GitHub Issue. Next, after the issue is filed and before any work is done, a feature branch should be created where the work will be done. 7.2.3.1 Branch Naming Conventions Keep it brief Use a hyphen as separators Example: R-pkg-skeleton 7.2.3.2 Branching Strategy FIMS uses a Scaled Trunk-Based Development branching strategy to streamline the integration of new code into the trunk. This strategy was mainly chosen for the following two reasons: Encourage small, frequent changes. Enable the release of bug fixes without new features. Some branches within NOAA-FIMS repositories have branch protection rules. For example, the branch protection rules for the main branch of NOAA-FIMS/FIMS are described on GitHub in the branch settings. 7.2.4 GitHub Pull Requests Once development within a feature branch is complete, a Pull Request (PR) should be initiated. PRs can be initiated with a draft status or marked as ready for review. The former will allow the code to be tested using tests available in GitHub actions without initiating a formal review. The latter will initiate the code review process. For repositories/branches with branch protection rules, the PR must be formally reviewed, approved, and pass all tests (see the section on GitHub Actions) before the branch can be merged into the chosen branch. Instructions for submitting your PR are available on the PR form on GitHub. PRs from forks are treated the same as PRs from within the repository, see the GitHub documentation on creating a PR from a fork for more information. 7.2.4.1 Pull Request Templates The templates for PRs are maintained in the .github/folder within the NOAA-FIMS/.github repository, same as NOAA-FIMS Issue templates. See the NOAA-FIMS/FIMS PR template here. 7.2.4.2 Pull Request Review Code review ensures health and continuous improvement of the FIMS codebase, while simultaneously helping FIMS developers become familiar with the codebase. Tools within GitHub allow for reviewers to analyze code changes, provide inline comments, and view change histories with ease. Google’s code review guide provides a useful set of guidelines for both reviewers and code authors. Below is a flowchart for the FIMS code review process. The author starts by submitting a PR, ensuring documentation, tests, and continuous integration checks are complete. The initiator of the PR must propose a reviewer (see Assigning Reviewers). The reviewer receives the review request and either executes the review independently or pairs with another team representative if assistance is needed. Based on the review, changes may be requested, which the author must address before approval. Once the PR is approved, the author must rebase and merge it into the desired branch. 7.2.4.2.1 Assigning Reviewers Reviewers of PRs for changes to the codebase in FIMS should be suggested by the author of the PR. For those FIMS Implementation Team Members that keep their status in GitHub current (see “Setting a status” for more information), authors of PRs can use the status information to prevent assigning a reviewer who is known to be “Busy”. If a review has been assigned to you and you don’t feel like you have the expertise to address it properly, please respond directly to the PR so a different reviewer can be found promptly or suggest someone to help you with the review. 7.2.4.2.2 Review Checklist While automated testing can assure the code structure and logic pass quality checks, human reviewers are required to evaluate things like functionality, readability, etc. Every PR is accompanied by an automatically generated checklist of major considerations for code reviews. 7.2.4.2.3 Reviewer Good Practices Good reviews require good review habits. Please use the guidance found at Conventional Comments for formatting/structuring your reviewer comments. Navigate to the Perforce Blog for nine best practices for code review and use the FIMS Style Guide to settle any style arguments. 7.2.5 GitHub Actions FIMS uses GitHub Actions to automate routine tasks such as testing, building and deploying websites, and notifying individuals. Some of the actions are built on reusable workflows available in {ghactions4r}, where reusable workflows allow for sharing of code. For the repositories in NOAA-FIMS that use GitHub actions, the actions can be found in .yml files that are stored in the .github/workflows directory. For example YAML files in .github/workflows of the NOAA-FIMS/FIMS repository specify the setup for the GitHub Actions for the source code of FIMS. 7.2.5.1 Example Actions call-r-cmd-check runs R CMD Check on the FIMS R package using the current version of R across three operating systems, Windows, Linux (Ubuntu), and OSX. R CMD Check ensures that the FIMS package can be downloaded without error. To replicate the GitHub Actions workflow locally, use devtools::check(). run-clang-tidy runs checks while compiling the C++ code. If this run fails, fixes need to be made to the C++ code to address the issue identified. run-googletest runs the GoogleTest C++ unit tests and benchmarking. If this run fails, then fixes need to be made to the C++ code and/or the GoogleTest C++ unit tests. To replicate this GitHub Actions workflow locally, follow instructions in the testing section. 7.2.5.2 Debugging Broken GitHub Actions GitHub Actions can fail for many reasons, so debugging is necessary to find the cause of the failing run. The tips found below can be helpful for determining why the action failed. Ask for help as needed! Some members of the FIMS team who have experience debugging GitHub Actions are Bai, Kathryn, and Ian. Investigate why the run failed by looking at the log file. GitHub provides some guidance on what is contained in the log file. Try to replicate the problem locally. For example, if the call-r-cmd-check run fails during the testthat tests, try running the testthat tests locally (e.g., using devtools::test() in an R session). If the problem can be replicated, try to fix locally by fixing one test or issue at a time. Then push the changes up to GitHub and monitor the new GitHub Action run. Check if the problem is present across all investigated operating systems because it might be operating system specific and not reproducible on your machine. For example, if using Windows locally, it may be an issue specific to Mac or Linux. Sometimes, runs may fail because a particular dependency was not available at the exact point in time need for the run (e.g., maybe R did not install because the R executable could not be downloaded); if that is the case, wait a few hours to a day and try to rerun. If it continues to fail for more than a day, a change in the GitHub Action .yml file may be needed. 7.3 git git is a distributed version control system that tracks files. All files within NOAA-FIMS are tracked using git and GitHub (see the section on GitHub) is used as a central server. The use of git stops the need for saving files with file_1.txt and file_2.txt. 7.3.1 git Example Use the following commands to (a) move to the local branch that you want your feature branch to be based off of, e.g., main in the example below; and (b) create a new branch, where you will replace with the name of your feature branch (see Branch Naming Conventions) and check it out. $ git checkout main $ git checkout -b &lt;branch-name&gt; Periodically rebase your feature branch with the branch you plan on merging into in the future by (a) fetching all the changes stored in GitHub for the branches in your clone and (b) rebasing your feature branch, e.g., here we rebase to origin/main because we eventually want to merge into main. We can rebase to any remote or local branch though. Be careful when rebasing if you have already pushed your feature branch to GitHub because rebasing will rewrite your commit hashes in your feature branch. $ git fetch -a $ git rebase origin/main While editing code, commit regularly following commit messages guidelines by (a) adding the changed files to the que and (2) committing them to the feature branch with a thoughtful commit message. If you configure your editor for git you can remove the -m argument and use a text file to make a more meaningful commit message with multiple lines. $ git add &lt;filename&gt; $ git commit -m &quot;feat: 50 character description&quot; &quot;Longer description&quot; Consider interactively rebasing your commits to squash similar commits into a single commit or rearrange the order of your commits. The following example is for the situation where you want to look at the last ten commits. $ git rebase -i head~10 Push your committed changes to GitHub. $ git push origin &lt;branch-name&gt; When you are finished making changes to your feature branch, navigate to GitHub and open a pull request to the desired branch, e.g., main in this example. Once the PR is approved and merged into the desired branch you (a) switch to a different branch and (b) delete the local version of your feature branch. Note that you might have to use -D instead of the lower-case version if you want to force the removal of the branch given that we use a rebase strategy and the commit hashes might have changed, thus git to think that the feature branch has not been merged into main because your local version of the feature branch might have different hashes than the remote version. $ git checkout main $ git branch -d &lt;branch-name&gt; "],["hpp-template-for-c-modules.html", "Chapter 8 .hpp template for C++ modules", " Chapter 8 .hpp template for C++ modules In this section we will describe how to structure a new .hpp file in FIMS. // tmplate.hpp // Fisheries Integrated Modeling System (FIMS) //define the header gaurd #ifndef template_hpp #define template_hpp //inherit from model_base #include &quot;../common.hpp&quot; #include &lt;iostream&gt; /** * In this example, we utilize the concept of inheritence and * polymorphism (https://www.geeksforgeeks.org/polymorphism-in-c/). All * classes inherit from model_base. Name1 and Name2 inherit from NameBase. * Classes Name1 and Name2 must implement they&#39;re own version of * &quot;virtual T evaluate(const T&amp; t)&quot;, which will have unique logic. */ /* * fims namespace */ namespace fims{ /** * NameBase class. Inherits from model_base. */ template &lt;class T&gt; class NameBase: public model_base&lt;T&gt;{ //note that model_base gets template parameter T. protected: public: virtual T Evaluate(const T&amp; t)=0; //&quot;= 0;&quot; means this must be implemented in child. }; /* * Template class inherits from NameBase */ template &lt;class T&gt; class Name1: public NameBase&lt;T&gt;{ public: /* *Default constructor *Initialize any memory here. */ Name1(){ } /** * Destructor; this method destructs Name1 object. * Delete any allocated memory here. */ ~ Name1(){ std::cout &lt;&lt;&quot;I just deleted Name1 object&quot; &lt;&lt; std::endl; } /** * Note: this function must have the same signature as evaluate in NameBase. * Overloaded virtual function. This is polymorphism, meaning the * signature has the same appearance, but the function itself has unique logic. * * @param t * @return t+1 */ virtual T Evaluate(const T&amp; t) { std::cout&lt;&lt;&quot;evaluate in Name1 received &quot;&lt;&lt;t&lt;&lt; &quot;as a method parameter, returning &quot;&lt;&lt;(t+1)&lt;&lt;std::endl; return t+1; //unique logic for Name1 class } }; /* * Template class inherits from NameBase */ template &lt;class T&gt; class Name2: public NameBase&lt;T&gt;{ public: /* *Default constructor. *Initialize any memory here. */ Name2(){ } /** * Destructor; this method destructs the Name2 object. * Delete any allocated memory here. */ ~ Name2(){ std::cout &lt;&lt;&quot;I just deleted Name2 object&quot; &lt;&lt; std::endl; } /** * Note: this function must have the same signature as evaluate in NameBase. * Overloaded virtual function. This is polymorphism, meaning the * signature has the same appearance, but the function itself has unique logic. * * @param t * @return t^2 */ virtual T Evaluate(const T&amp; t) { std::cout&lt;&lt;&quot;evaluate in Name2 received &quot;&lt;&lt;t&lt;&lt; &quot;as a method parameter, returning &quot;&lt;&lt;(t*t)&lt;&lt;std::endl; return t*t; //unique logic for Name2 class } }; /** * Add additional implementations below. */ } //end namespace /** *Example usage: * * void main(int argc, char** argv){ * NameBase&lt;double&gt;* name = NULL; //pointer to a NameBase object * Name1&lt;double&gt; n1; //inherits from NameBase * Name2&lt;double&gt; n2; //inherits from NameBase * * name = &amp;n1; //name now points to n1 * name-&gt;Evalute(2.0); //unique logic for n1 * * name = &amp;n2; //name now points to n2 * name-&gt;Evalute(2.0); //unique logic for n2 * } * * Output: * evaluate in Name1 received 2 as a method parameter, returning 3 * evaluate in Name2 received 2 as a method parameter, returning 4 * */ #endif /*template_hpp */ "],["documentation-template.html", "Chapter 9 Documentation Template 9.1 Writing function reference 9.2 Writing a vignette", " Chapter 9 Documentation Template Below, are specific, brief instructions on developer responsibilities for FIMS regarding documentation. For more information about code documentation in general, please see the toolbox blog post on code documentation. 9.1 Writing function reference Function reference can be written inline in comments above the function in either C++ or R. Doxygen and Roxygen in C++ and R, respectively, are used to render the documentation. Both can include LaTeX syntax to denote equations and both use @ tags to name components of the function reference. Below is an example from C++ code. /** * @brief This function calculates the von Bertalanffy growth curve. * \\f$ * * length\\_at\\_age = lmin + (lmax - lmin)*\\frac{(1.0 - c^ {(age - a\\_min)}))}{(1.0 - c^{(a\\_max - a\\_min)})} * * \\f$ * * @param age * @param sex * @return length\\_at\\_age */ which can be be rendered using via the following lines in the Command Prompt: cmake -S. -B build -G Ninja cmake --build build The only difference between the syntax for R and C++ code is how comments are denoted in the language. Below is an example from R code. #&#39; This function calculates the von Bertalanffy growth curve. #&#39; #&#39; @param age #&#39; @param sex #&#39; @return length_at_age which can be rendered in R with devtools::document(). You should, at minimum, include the tags @param, @return, and @examples in your documentation for all exported functions. Functions that are only called internally do not require an @examples tag. See the r-lib for all available tags and best practices. 9.2 Writing a vignette Vignettes can be a helpful tool to let users to know how to use functions. If you include a vignette for your function, you can link to it in the Roxygen documentation with the following code. #&#39; \\code{vignette(&quot;help&quot;, package = &quot;mypkg&quot;)} "],["testing.html", "Chapter 10 Testing 10.1 Introduction 10.2 C++ unit testing and benchmarking 10.3 Templates for GoogleTest testing 10.4 R testing", " Chapter 10 Testing 10.1 Introduction Our testing framework includes several types of tests. Unit and functional tests are created for individual functions and modules, respectively, where unit tests test each of the smallest components and functional tests ensure that the application of small components function within the requirements. Integration tests verify that modules work well together. Run-time tests include checks that are integrated into the code to catch errors related to user input. Regression testing and platform compatibility testing are executed before pre-releasing FIMS to ensure that previously tested pieces are still performing after the code has been changed on all platforms of interest. Beta-testing is used to gather feedback from users (i.e., members of FIMS Implementation Team and other users) during the pre-release stage. Finally, one-off testing is used for replicating and fixing user-reported bugs. Some of these one-off tests may eventually be integrated into the permanent testing framework. Or, if while you are coding you find a useful interactive tests that helped you build something, then it should be converted into {testthat} or GoogleTest tests. FIMS uses GoogleTest to build a C++ unit testing framework and {testthat} to build an R testing framework. FIMS uses Google Benchmark to measure the real time and CPU time used for running the produced binaries. All required software for testing can be installed using the instructions in the Software to install section. 10.2 C++ unit testing and benchmarking Inside of your cloned version of FIMS, the file CMakeLists.txt, in the top-level directory, instructs Cmake on how to create the build files, including setting up Google Test. The Google Test code is in tests/gtest. Within this subdirectory is another CMakeLists.txt that contains additional specifications on how to register the individual tests. 10.2.1 Build and run the tests The following commands on the command line (note that Windows users cannot use Git bash and must use a native Windows shell) execute the outlined steps and are needed to build the tests: Generate the build system using Ninja as the generator, which creates the build directory. Use Cmake to build in the build directory in parallel using 16 jobs but --parallel 16 can be deleted. Run the tests using ctest in parallel using 16 jobs but --parallel 16 can be deleted. cmake -S . -B build -G Ninja cmake --build build --parallel 16 ctest --test-dir build --parallel 16 The output from running the tests should look something like the following: Internal ctest changing into directory: C:/github_repos/NOAA-FIMS_org/FIMS/build Test project C:/github_repos/NOAA-FIMS_org/FIMS/build Start 1: dlognorm.use_double_inputs 1/5 Test #1: dlognorm.use_double_inputs ....... Passed 0.04 sec Start 2: dlognorm.use_int_inputs 2/5 Test #2: dlognorm.use_int_inputs .......... Passed 0.04 sec Start 3: modelTest.eta 3/5 Test #3: modelTest.eta .................... Passed 0.04 sec Start 4: modelTest.nll 4/5 Test #4: modelTest.nll .................... Passed 0.04 sec Start 5: modelTest.evaluate 5/5 Test #5: modelTest.evaluate ............... Passed 0.04 sec 100% tests passed, 0 tests failed out of 5 10.2.2 Adding a C++ test Create a file dlognorm.hpp within the src subfolder that contains a simple function: #include &lt;cmath&gt; template&lt;class Type&gt; Type dlognorm(Type x, Type meanlog, Type sdlog){ Type resid = (log(x)-meanlog)/sdlog; Type logres = -log(sqrt(2*M_PI)) - log(sdlog) - Type(0.5)*resid*resid - log(x); return logres; } Then, create dlognorm-unit.cpp in tests/gtest that has a test suite for the dlognorm function: #include &quot;gtest/gtest.h&quot; #include &quot;../../src/dlognorm.hpp&quot; // # R code that generates true values for the test // dlnorm(1.0, 0.0, 1.0, TRUE) = -0.9189385 // dlnorm(5.0, 10.0, 2.5, TRUE) = -9.07679 namespace { // TestSuiteName: dlognormTest; TestName: DoubleInput and IntInput // Test dlognorm with double input values TEST(dlognormTest, DoubleInput) { EXPECT_NEAR( dlognorm(1.0, 0.0, 1.0) , -0.9189385 , 0.0001 ); EXPECT_NEAR( dlognorm(5.0, 10.0, 2.5) , -9.07679 , 0.0001 ); } // Test dlognorm with integer input values TEST(dlognormTest, IntInput) { EXPECT_NEAR( dlognorm(1, 0, 1) , -0.9189385 , 0.0001 ); } } EXPECT_NEAR(val1, val2, absolute_error) verifies that the difference between val1 and val2 does not exceed the absolute error bound absolute_error. EXPECT_NE(val1, val2) verifies that val1 is not equal to val2. See GoogleTest assertions reference for more EXPECT_ macros. Finally, the test must be added to tests/gtest/CMakeLists.txt before running the tests. Add the following contents to the end of tests/gtest/CMakeLists.txt to enable testing in CMake, declare the C++ test binary you want to build (dlognorm_test), and link it to GoogleTest (gtest_main). : add_executable(dlognorm_test dlognorm-unit.cpp ) target_include_directories(dlognorm_test PUBLIC ${CMAKE_SOURCE_DIR}/../ ) target_link_libraries(dlognorm_test gtest_main ) include(GoogleTest) gtest_discover_tests(dlognorm_test) Now you can build and run your test using the instructions in Build and run the tests. The output when running ctest will look something like the following, note that there is a failing test: Internal ctest changing into directory: C:/Users/Kathryn.Doering/Documents/testing/FIMS/build Test project C:/Users/Kathryn.Doering/Documents/testing/FIMS/build Start 1: dlognorm.use_double_inputs 1/7 Test #1: dlognorm.use_double_inputs ....... Passed 0.04 sec Start 2: dlognorm.use_int_inputs 2/7 Test #2: dlognorm.use_int_inputs .......... Passed 0.04 sec Start 3: modelTest.eta 3/7 Test #3: modelTest.eta .................... Passed 0.04 sec Start 4: modelTest.nll 4/7 Test #4: modelTest.nll .................... Passed 0.04 sec Start 5: modelTest.evaluate 5/7 Test #5: modelTest.evaluate ............... Passed 0.04 sec Start 6: dlognormTest.DoubleInput 6/7 Test #6: dlognormTest.DoubleInput ......... Passed 0.04 sec Start 7: dlognormTest.IntInput 7/7 Test #7: dlognormTest.IntInput ............***Failed 0.04 sec 86% tests passed, 1 tests failed out of 7 Total Test time (real) = 0.28 sec The following tests FAILED: 7 - dlognormTest.IntInput (Failed) Errors while running CTest Output from these tests are in: C:/Users/Kathryn.Doering/Documents/testing/FIMS/build/Testing/Temporary/LastTest.log Use &quot;--rerun-failed --output-on-failure&quot; to re-run the failed cases verbosely. 10.2.3 Debugging a C++ test There are two ways to debug a C++ test, interactively using gdb or via print statements. To debug C++ code (e.g., segmentation error/memory corruption) using gdb: cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Debug cmake --build build --parallel 16 ctest --test-dir build --parallel 16 gdb ./build/tests/gtest/population_dynamics_population.exe c // to continue without paging run // to see which line of code is broken print this-&gt;log_naa // for example, print this-&gt;log_naa to see the value of log_naa; print i // for example, print i from the broken for loop bt // backtrace q // to quit To debug C++ code with print statements you must update the C++ in the desired .hpp file by adding std::ofstream out(“file_name.txt”) and using out &lt;&lt; variable; to print out values of the variable. The output of the print statements will be in FIMS/build/tests/gtest/debug.txt after you run the cmake and ctest calls the instructions in Build and run the tests. nfleets = fleets.size(); std::ofstream out(&quot;debug.txt&quot;); out &lt;&lt;nfleets; More complex examples with text identifying the quantities out &lt;&lt;&quot; fleet_index: &quot;&lt;&lt;fleet_index&lt;&lt;&quot; index_yaf: &quot;&lt;&lt;index_yaf&lt;&lt;&quot; index_yf: &quot;&lt;&lt;index_yf&lt;&lt;&quot;\\n&quot;; out &lt;&lt;&quot; population.Fmort[index_yf]: &quot;&lt;&lt;population.Fmort[index_yf]&lt;&lt;&quot;\\n&quot;; 10.2.4 Benchmark example Google Benchmark measures the real time and CPU time used for running the produced binary. We will continue using the dlognorm.hpp example. Create dlognorm_benchmark.cpp in tests/gtest with the following code to run the dlognorm function and use BENCHMARK to see how long it takes. #include &quot;benchmark/benchmark.h&quot; #include &quot;../../src/dlognorm.hpp&quot; void BM_dlgnorm(benchmark::State&amp; state) { for (auto _ : state) dlognorm(5.0, 10.0, 2.5); } BENCHMARK(BM_dlgnorm); Next, the following needs to be added to the end of tests/gtest/CMakeLists.txt: FetchContent_Declare( googlebenchmark URL https://github.com/google/benchmark/archive/refs/tags/v1.6.0.zip ) FetchContent_MakeAvailable(googlebenchmark) add_executable(dlognorm_benchmark dlognorm_benchmark.cpp ) target_include_directories(dlognorm_benchmark PUBLIC ${CMAKE_SOURCE_DIR}/../ ) target_link_libraries(dlognorm_benchmark benchmark_main ) To run the benchmark, run cmake sending output to the build subfolder and run the created executable: cmake --build build build/tests/gtest/dlognorm_benchmark.exe The output from dlognorm_benchmark.exe might look like this: Run on (8 X 2112 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) ***WARNING*** Library was built as DEBUG. Timings may be affected. ----------------------------------------------------- Benchmark Time CPU Iterations ----------------------------------------------------- BM_dlgnorm 153 ns 153 ns 4480000 10.2.5 Clean up after running C++ tests After running the examples above, the build generates files (i.e., the source code, libraries, and executables) and saves the files in the build subfolder. The example above demonstrates an “out-of-source” build which puts generated files in a completely separate directory, so that the source tree is unchanged after running tests. Using a separate source and build tree reduces the need to delete files that differ between builds. If you still would like to delete CMake-generated files, just delete the build folder, and then build and run tests by repeating the commands below. The files from the build folder are included in the FIMS repository’s .gitignore file, so should not be pushed to the FIMS repository. For simple C++ functions like the examples above, we do not need to clean up the tests. Clean up is only necessary in a few situations. If memory for an object was allocated during testing and not deallocated then the object needs to be deleted (e.g., delete object). If you used a test fixture from GoogleTest to use the same data configuration for multiple tests, TearDown() can be used to clean up the test and then the test fixture will be deleted. See GoogleTest user’s guide for more details. If you do not want to keep any of the files produced by the example and want to completely clear any uncommitted changes and files from the git repo, run git restore ., which removes any committed changes in files tracked by git or git clean -fd to get remove all untracked files in the repository. 10.3 Templates for GoogleTest testing This section includes templates for creating unit tests and benchmarks. This is the code that would go into the .cpp files in tests/gtest. 10.3.1 C++ test templates 10.3.1.1 Unit test template #include &quot;gtest/gtest.h&quot; #include &quot;../../src/code.hpp&quot; // # R code that generates true values for the test namespace { // Description of Test 1 TEST(TestSuiteName, Test1Name) { ... test body ... } // Description of Test 2 TEST(TestSuiteName, Test2Name) { ... test body ... } } 10.3.1.2 Benchmark template #include &quot;benchmark/benchmark.h&quot; #include &quot;../../src/code.hpp&quot; void BM_FunctionName(benchmark::State&amp; state) { for (auto _ : state) // This code gets timed Function() } // Register the function as a benchmark BENCHMARK(BM_FunctionName); 10.3.1.3 tests/gtest/CMakeLists.txt template These lines are added each time a new test, e.g., TestSuiteName1, is added: // Add test suite 1 add_executable(TestSuiteName1 test1.cpp ) target_link_libraries(TestSuiteName1 gtest_main ) gtest_discover_tests(TestSuiteName1) These lines are added each time a new benchmark, e.g., benchmark1, is added: // Add benchmark 1 add_executable(benchmark1 benchmark1.cpp ) target_link_libraries(benchmark1 benchmark_main ) 10.4 R testing R tests are written using {testthat}, which can be installed as an R package. More details on {testthat} can be found in the testing chapter of R packages. 10.4.1 Testing FIMS locally To test FIMS R functions, interactively and locally, use devtools::install() rather than devtools::load_all() because using load_all() will turn on the debugger, bloating the .o file and may lead to a compilation error (see Fixing Fatal Error for more information). 10.4.2 Testing using gdbsource You can interactively debug C++ code using TMB::gdbsource() in RStudio. 10.4.3 and file organization Group functions and their helpers together, i.e., the “main function plus helpers” approach. {testthat} tests that are a test of Rcpp code should be called test-rcpp-[description].R. Integration tests that do not have a corresponding .R file should use the follwing convention: test-integration-[description].R. 10.4.4 R template Naming conventions for {testthat} files follow the tidyverse test convention as well as the using test-rcpp-[description].R for tests of Rcpp code and test-integration-[description].R for integration tests without a corresponding R function. The format for an individual testthat test is is: test_that(&quot;TestName&quot;, { ...test body... }) 10.4.5 Random numbers Simulation results might be dependent on the order of calls, leading to failed tests just because different random numbers are used or the order of the simulation changes through model development (see FIMS-planning discussion 25 for details). Below are some potential soluations. - Add a TRUE/FALSE parameter in each FIMS simulation module for setting up testing seed. When testing the module, set the parameter to TRUE to fix the seed number in R and conduct tests. If adding a TRUE/FALSE parameter does not work as expected, then carefully check simulated data from each component and make sure it is not a model coding error. - Use set.seed() from R to set the seed and investigate using {rstream} to generate multiple streams of random numbers to associate distinct streams of random numbers with different sources of randomness. {rstream} was specifically designed to address the issue of needing very long streams of pseudo-random numbers for parallel computations. See the rstream paper and RngStreams for more details. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
